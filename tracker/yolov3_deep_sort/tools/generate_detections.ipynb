{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# vim: expandtab:ts=4:sw=4\n",
        "import os\n",
        "import errno\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow.compat.v1 as tf\n",
        "    \n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "def _run_in_batches(f, data_dict, out, batch_size):\n",
        "    data_len = len(out)\n",
        "    num_batches = int(data_len / batch_size)\n",
        "\n",
        "    s, e = 0, 0\n",
        "    for i in range(num_batches):\n",
        "        s, e = i * batch_size, (i + 1) * batch_size\n",
        "        batch_data_dict = {k: v[s:e] for k, v in data_dict.items()}\n",
        "        out[s:e] = f(batch_data_dict)\n",
        "    if e < len(out):\n",
        "        batch_data_dict = {k: v[e:] for k, v in data_dict.items()}\n",
        "        out[e:] = f(batch_data_dict)\n",
        "\n",
        "\n",
        "def extract_image_patch(image, bbox, patch_shape):\n",
        "    \"\"\"Extract image patch from bounding box.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : ndarray\n",
        "        The full image.\n",
        "    bbox : array_like\n",
        "        The bounding box in format (x, y, width, height).\n",
        "    patch_shape : Optional[array_like]\n",
        "        This parameter can be used to enforce a desired patch shape\n",
        "        (height, width). First, the `bbox` is adapted to the aspect ratio\n",
        "        of the patch shape, then it is clipped at the image boundaries.\n",
        "        If None, the shape is computed from :arg:`bbox`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray | NoneType\n",
        "        An image patch showing the :arg:`bbox`, optionally reshaped to\n",
        "        :arg:`patch_shape`.\n",
        "        Returns None if the bounding box is empty or fully outside of the image\n",
        "        boundaries.\n",
        "\n",
        "    \"\"\"\n",
        "    bbox = np.array(bbox)\n",
        "    if patch_shape is not None:\n",
        "        # correct aspect ratio to patch shape\n",
        "        target_aspect = float(patch_shape[1]) / patch_shape[0]\n",
        "        new_width = target_aspect * bbox[3]\n",
        "        bbox[0] -= (new_width - bbox[2]) / 2\n",
        "        bbox[2] = new_width\n",
        "\n",
        "    # convert to top left, bottom right\n",
        "    bbox[2:] += bbox[:2]\n",
        "    bbox = bbox.astype(np.int)\n",
        "\n",
        "    # clip at image boundaries\n",
        "    bbox[:2] = np.maximum(0, bbox[:2])\n",
        "    bbox[2:] = np.minimum(np.asarray(image.shape[:2][::-1]) - 1, bbox[2:])\n",
        "    if np.any(bbox[:2] >= bbox[2:]):\n",
        "        return None\n",
        "    sx, sy, ex, ey = bbox\n",
        "    image = image[sy:ey, sx:ex]\n",
        "    image = cv2.resize(image, tuple(patch_shape[::-1]))\n",
        "    return image\n",
        "\n",
        "\n",
        "class ImageEncoder(object):\n",
        "\n",
        "    def __init__(self, checkpoint_filename, input_name=\"images\",\n",
        "                 output_name=\"features\"):\n",
        "        self.session = tf.Session()\n",
        "        with tf.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(file_handle.read())\n",
        "        tf.import_graph_def(graph_def, name=\"net\")\n",
        "        self.input_var = tf.get_default_graph().get_tensor_by_name(\n",
        "            \"%s:0\" % input_name)\n",
        "        self.output_var = tf.get_default_graph().get_tensor_by_name(\n",
        "            \"%s:0\" % output_name)\n",
        "\n",
        "        assert len(self.output_var.get_shape()) == 2\n",
        "        assert len(self.input_var.get_shape()) == 4\n",
        "        self.feature_dim = self.output_var.get_shape().as_list()[-1]\n",
        "        self.image_shape = self.input_var.get_shape().as_list()[1:]\n",
        "\n",
        "    def __call__(self, data_x, batch_size=32):\n",
        "        out = np.zeros((len(data_x), self.feature_dim), np.float32)\n",
        "        _run_in_batches(\n",
        "            lambda x: self.session.run(self.output_var, feed_dict=x),\n",
        "            {self.input_var: data_x}, out, batch_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "def create_box_encoder(model_filename, input_name=\"images\",\n",
        "                       output_name=\"features\", batch_size=32):\n",
        "    image_encoder = ImageEncoder(model_filename, input_name, output_name)\n",
        "    image_shape = image_encoder.image_shape\n",
        "\n",
        "    def encoder(image, boxes):\n",
        "        image_patches = []\n",
        "        for box in boxes:\n",
        "            patch = extract_image_patch(image, box, image_shape[:2])\n",
        "            if patch is None:\n",
        "                print(\"WARNING: Failed to extract image patch: %s.\" % str(box))\n",
        "                patch = np.random.uniform(\n",
        "                    0., 255., image_shape).astype(np.uint8)\n",
        "            image_patches.append(patch)\n",
        "        image_patches = np.asarray(image_patches)\n",
        "        return image_encoder(image_patches, batch_size)\n",
        "\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def generate_detections(encoder, mot_dir, output_dir, detection_dir=None):\n",
        "    \"\"\"Generate detections with features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    encoder : Callable[image, ndarray] -> ndarray\n",
        "        The encoder function takes as input a BGR color image and a matrix of\n",
        "        bounding boxes in format `(x, y, w, h)` and returns a matrix of\n",
        "        corresponding feature vectors.\n",
        "    mot_dir : str\n",
        "        Path to the MOTChallenge directory (can be either train or test).\n",
        "    output_dir\n",
        "        Path to the output directory. Will be created if it does not exist.\n",
        "    detection_dir\n",
        "        Path to custom detections. The directory structure should be the default\n",
        "        MOTChallenge structure: `[sequence]/det/det.txt`. If None, uses the\n",
        "        standard MOTChallenge detections.\n",
        "\n",
        "    \"\"\"\n",
        "    if detection_dir is None:\n",
        "        detection_dir = mot_dir\n",
        "    try:\n",
        "        os.makedirs(output_dir)\n",
        "    except OSError as exception:\n",
        "        if exception.errno == errno.EEXIST and os.path.isdir(output_dir):\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Failed to created output directory '%s'\" % output_dir)\n",
        "\n",
        "    for sequence in os.listdir(mot_dir):\n",
        "        print(\"Processing %s\" % sequence)\n",
        "        sequence_dir = os.path.join(mot_dir, sequence)\n",
        "\n",
        "        image_dir = os.path.join(sequence_dir, \"img1\")\n",
        "        image_filenames = {\n",
        "            int(os.path.splitext(f)[0]): os.path.join(image_dir, f)\n",
        "            for f in os.listdir(image_dir)}\n",
        "\n",
        "        detection_file = os.path.join(\n",
        "            detection_dir, sequence, \"det/det.txt\")\n",
        "        detections_in = np.loadtxt(detection_file, delimiter=',')\n",
        "        detections_out = []\n",
        "\n",
        "        frame_indices = detections_in[:, 0].astype(np.int)\n",
        "        min_frame_idx = frame_indices.astype(np.int).min()\n",
        "        max_frame_idx = frame_indices.astype(np.int).max()\n",
        "        for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
        "            print(\"Frame %05d/%05d\" % (frame_idx, max_frame_idx))\n",
        "            mask = frame_indices == frame_idx\n",
        "            rows = detections_in[mask]\n",
        "\n",
        "            if frame_idx not in image_filenames:\n",
        "                print(\"WARNING could not find image for frame %d\" % frame_idx)\n",
        "                continue\n",
        "            bgr_image = cv2.imread(\n",
        "                image_filenames[frame_idx], cv2.IMREAD_COLOR)\n",
        "            features = encoder(bgr_image, rows[:, 2:6].copy())\n",
        "            detections_out += [np.r_[(row, feature)] for row, feature\n",
        "                               in zip(rows, features)]\n",
        "\n",
        "        output_filename = os.path.join(output_dir, \"%s.npy\" % sequence)\n",
        "        np.save(\n",
        "            output_filename, np.asarray(detections_out), allow_pickle=False)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"Parse command line arguments.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Re-ID feature extractor\")\n",
        "    parser.add_argument(\n",
        "        \"--model\",\n",
        "        default=\"resources/networks/mars-small128.pb\",\n",
        "        help=\"Path to freezed inference graph protobuf.\")\n",
        "    parser.add_argument(\n",
        "        \"--mot_dir\", help=\"Path to MOTChallenge directory (train or test)\",\n",
        "        required=True)\n",
        "    parser.add_argument(\n",
        "        \"--detection_dir\", help=\"Path to custom detections. Defaults to \"\n",
        "        \"standard MOT detections Directory structure should be the default \"\n",
        "        \"MOTChallenge structure: [sequence]/det/det.txt\", default=None)\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\", help=\"Output directory. Will be created if it does not\"\n",
        "        \" exist.\", default=\"detections\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    encoder = create_box_encoder(args.model, batch_size=32)\n",
        "    generate_detections(encoder, args.mot_dir, args.output_dir,\n",
        "                        args.detection_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}