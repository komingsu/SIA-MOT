{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15057966733889188417\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3643801600\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5031048753523010411\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rh987\\AppData\\Roaming\\Python\\Python39\\site-packages\\albumentations\\imgaug\\transforms.py:346: FutureWarning: This IAAAffine is deprecated. Please use Affine instead\n",
      "  warnings.warn(\"This IAAAffine is deprecated. Please use Affine instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from yolo_core.dataset2 import Dataset\n",
    "from yolo_core.yolov4 import Create_Yolo, compute_loss\n",
    "from yolo_core.utils import Load_Yolo_model, postprocess_boxes, nms, image_preprocess, activate_list_in_dataframe\n",
    "from configuration import *\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "train length : 8064\n",
      "test length : 6634\n",
      "epoch:  1/5, step:  100/4032, lr:0.000002, giou_loss: 130.42, conf_loss:1446.28, prob_loss: 228.05, total_loss:1804.75\n",
      "something wrong, check preprocess_true_boxes func\n"
     ]
    }
   ],
   "source": [
    "# Create checkpoints folder 폴더 생성\n",
    "if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER):\n",
    "    os.makedirs(TRAIN_CHECKPOINTS_FOLDER)\n",
    "    \n",
    "def main():\n",
    "    global TRAIN_FROM_CHECKPOINT\n",
    "    \n",
    "    # 메모리 과부하 방지 체크\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    print(f'GPUs {gpus}')\n",
    "    if len(gpus) > 0:\n",
    "        try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        except RuntimeError: pass\n",
    "\n",
    "    # logging 폴더 생성\n",
    "    if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "    writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "    # 데이터 셋\n",
    "    trainset = Dataset('train')\n",
    "    testset = Dataset('test')\n",
    "\n",
    "    # 스텝 체크\n",
    "    steps_per_epoch = len(trainset)\n",
    "    global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "    warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "    total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "\n",
    "    # 모델 호출\n",
    "    model = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "    # optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # train step 정의\n",
    "    def train_step(image_data, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_result = model(image_data, training=True)\n",
    "            # loss init\n",
    "            giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "            # optimizing process\n",
    "            grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "            for i in range(grid):\n",
    "                conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "                giou_loss += loss_items[0]\n",
    "                conf_loss += loss_items[1]\n",
    "                prob_loss += loss_items[2]\n",
    "\n",
    "            total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "            gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # update learning rate\n",
    "            global_steps.assign_add(1)\n",
    "            if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "                lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "            else:\n",
    "                lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                    (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "            optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "            # writing summary data\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "            writer.flush()\n",
    "            \n",
    "        return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "\n",
    "    # valid step 정의\n",
    "    def val_step(image_data, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_result = model(image_data, training=False)\n",
    "            giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "            # optimizing process\n",
    "            grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "            for i in range(grid):\n",
    "                conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "                giou_loss += loss_items[0]\n",
    "                conf_loss += loss_items[1]\n",
    "                prob_loss += loss_items[2]\n",
    "\n",
    "            total_loss = giou_loss + conf_loss + prob_loss\n",
    "            \n",
    "        return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "    \n",
    "    # 최종 점수 확인\n",
    "    mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "\n",
    "    # epochs loop\n",
    "    best_val_loss = 1000 # Best loss init (best weight 일 때 저장)\n",
    "    for epoch in range(TRAIN_EPOCHS):\n",
    "        for image_data, target in trainset:\n",
    "            results = train_step(image_data, target)\n",
    "            cur_step = results[0]%steps_per_epoch\n",
    "            \n",
    "            # print(\"Step :\", cur_step+1)\n",
    "            if (cur_step+1)%100 == 0:\n",
    "                print(\"epoch:{:3d}/{}, step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "                      .format(epoch+1, TRAIN_EPOCHS, cur_step+1, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "                                \n",
    "            if (cur_step+1)%4000 == 0 or (cur_step+1) == steps_per_epoch:\n",
    "                save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, DATA_TYPE)\n",
    "                model.save_weights(save_directory)\n",
    "\n",
    "        if len(testset) == 0:\n",
    "            print(\"configure TEST options to validate model\")\n",
    "            model.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, DATA_TYPE))\n",
    "            continue\n",
    "        \n",
    "        count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "        for image_data, target in testset:\n",
    "            results = val_step(image_data, target)\n",
    "            count += 1\n",
    "            giou_val += results[0]\n",
    "            conf_val += results[1]\n",
    "            prob_val += results[2]\n",
    "            total_val += results[3]\n",
    "\n",
    "\n",
    "        if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/count:\n",
    "            save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, DATA_TYPE+\"_best\")\n",
    "            model.save_weights(save_directory)\n",
    "            best_val_loss = total_val/count     \n",
    "            \n",
    "                   \n",
    "        # writing validate summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "        writer.flush()\n",
    "\n",
    "            \n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "              format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:6006/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"http://localhost:6006/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e919c1631ac42029c7b8817734f58e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test dataset의 ground-truth txt 생성\n",
    "\n",
    "import cv2\n",
    "\n",
    "GT_PATH = \"./input/ground-truth/\"\n",
    "DET_PATH = \"./input/detection-results/\"\n",
    "\n",
    "df = pd.read_csv(\"./data/test_detection_frame.csv\")\n",
    "df = activate_list_in_dataframe(df)\n",
    "# # ckpt_directory = \"checkpoints/baseline_yolov3_33/visdrone_best\"\n",
    "\n",
    "# # yolo = Load_Yolo_model(save_directory=ckpt_directory)\n",
    "\n",
    "img_path_arr = df[\"img_path\"].values\n",
    "x_min_arr = df[\"x_min\"].values\n",
    "x_max_arr = df[\"x_max\"].values\n",
    "y_min_arr = df[\"y_min\"].values\n",
    "y_max_arr = df[\"y_max\"].values\n",
    "class_arr = df[\"classes\"].values\n",
    "\n",
    "for idx in tqdm(range(len(df))):\n",
    "    name = os.path.split(img_path_arr[idx])[1]\n",
    "    name = os.path.splitext(name)[0]\n",
    "    GT_OUTPUT = os.path.join(GT_PATH, f\"{name}.txt\")\n",
    "\n",
    "    f = open(GT_OUTPUT, 'w')\n",
    "    for b_idx in range(len(x_min_arr[idx])):\n",
    "        write_data = []\n",
    "        write_data.append(str(class_arr[idx][b_idx]))\n",
    "        write_data.append(str(x_min_arr[idx][b_idx]))\n",
    "        write_data.append(str(y_min_arr[idx][b_idx]))\n",
    "        write_data.append(str(x_max_arr[idx][b_idx]))\n",
    "        write_data.append(str(y_max_arr[idx][b_idx]))\n",
    "        write_data = \" \".join(write_data)+\"\\n\"\n",
    "        f.write(write_data)\n",
    "    f.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4f1f499c5347e2bc699ea497b0296c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "DET_PATH = \"./input/detection-results/\"\n",
    "\n",
    "df = pd.read_csv(\"./data/test_detection_frame.csv\")\n",
    "df = activate_list_in_dataframe(df)\n",
    "ckpt_directory = \"checkpoints/baseline_yolov3/visdrone_best\"\n",
    "\n",
    "yolo = Load_Yolo_model(save_directory=ckpt_directory)\n",
    "\n",
    "img_path_arr = df[\"img_path\"].values\n",
    "\n",
    "for idx in tqdm(range(len(df))):\n",
    "    name = os.path.split(img_path_arr[idx])[1]\n",
    "    name = os.path.splitext(name)[0]\n",
    "    DET_OUTPUT = os.path.join(DET_PATH, f\"{name}.txt\")\n",
    "\n",
    "    original_image      = cv2.imread(img_path_arr[idx])\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    image_data = image_preprocess(np.copy(original_image), [416, 416])\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    pred_bbox = yolo.predict_step(image_data)\n",
    "        \n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image, 416, 0.3)\n",
    "    bboxes = nms(bboxes, 0.45, method='nms')\n",
    "\n",
    "    f = open(DET_OUTPUT, 'w')\n",
    "    for pred in bboxes:\n",
    "        pred = np.roll(pred, 2)\n",
    "        pred[0], pred[1] = pred[1], pred[0]\n",
    "        pred = pred.tolist()\n",
    "        pred[0] = int(pred[0])\n",
    "        pred[2] = int(pred[2])\n",
    "        pred[3] = int(pred[3])\n",
    "        pred[4] = int(pred[4])\n",
    "        pred[5] = int(pred[5])\n",
    "        write_data = \" \".join([str(i) for i in pred])+\"\\n\"\n",
    "        # print(write_data)\n",
    "        f.write(write_data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.37% = 0 AP \n",
      "16.54% = 1 AP \n",
      "52.84% = 2 AP \n",
      "mAP = 27.25%\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "!python mAP.py -na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m RESULT_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./result/baseline_yolov3_33\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(RESULT_PATH):\n\u001b[0;32m      5\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(RESULT_PATH)\n\u001b[0;32m      8\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./data/test_detection_frame.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "RESULT_PATH = \"./result/baseline_yolov3_33\"\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/test_detection_frame.csv\")\n",
    "df = activate_list_in_dataframe(df)\n",
    "ckpt_directory = \"checkpoints/baseline_yolov3_33/visdrone_best\"\n",
    "yolo = Load_Yolo_model(save_directory=ckpt_directory)\n",
    "\n",
    "for video_n in tqdm( df[\"video_name\"].unique()):\n",
    "    temp_df = df[df[\"video_name\"]==video_n]\n",
    "    img_paths = temp_df[\"img_path\"].values\n",
    "\n",
    "    output_path = os.path.join(RESULT_PATH,f\"{video_n}_pred.txt\")\n",
    "    f = open(output_path, 'w')\n",
    "\n",
    "    for frame_idx, img_path in enumerate(img_paths):\n",
    "        original_image      = cv2.imread(img_path)\n",
    "        original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        image_data = image_preprocess(np.copy(original_image), [416, 416])\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        pred_bbox = yolo.predict_step(image_data)\n",
    "            \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "        bboxes = postprocess_boxes(pred_bbox, original_image, 416, 0.3)\n",
    "        bboxes = nms(bboxes, 0.45, method='nms')\n",
    "\n",
    "\n",
    "        for pred in bboxes:\n",
    "            write_data = str(frame_idx)+\",\"+\",\".join([str(i) for i in pred])+\"\\n\"\n",
    "            f.write(write_data)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
