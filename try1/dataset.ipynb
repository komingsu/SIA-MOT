{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e939ec19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:35:05.850875Z",
     "start_time": "2023-07-14T05:35:05.845113Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "NUM_CLASSES = 11\n",
    "STRIDES = np.array([8,16,32])\n",
    "ANCHORS =(1.25,1.625, 2.0,3.75, 4.125,2.875, 1.875,3.8125, 3.875,2.8125, 3.6875,7.4375, 3.625,2.8125, 4.875,6.1875, 11.65625,10.1875)\n",
    "ANCHORS = np.array(ANCHORS).reshape(3,3,2) # 3개의 스케일\n",
    "ANCHORS[0]/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca02b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T04:23:40.797936Z",
     "start_time": "2023-07-14T04:23:39.921369Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_TFRECORD_PATH = \"./EDA/train_dataset.tfrecord\"\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_SIZE = 416\n",
    "scale = 1.1\n",
    "\n",
    "ANCHORS = [\n",
    "    [[10, 13], [16, 30], [33, 23]],\n",
    "    [[30, 61], [62, 45], [59,119]],\n",
    "    [[116, 90], [156, 198], [373, 326]]\n",
    "]\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "TRAIN_INPUT_SIZE = 416\n",
    "STRIDES = tf.constant([8, 16, 32],dtype=tf.float32)\n",
    "TRAIN_OUTPUT_SIZE = TRAIN_INPUT_SIZE //STRIDES\n",
    "ANCHOR_PER_SCALE = 3\n",
    "MAX_BBOX_PER_SCALE = 100\n",
    "IOU_ANCHOR_THRESH = 0.3\n",
    "OUTPUT_LEVELS = STRIDES.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b8318",
   "metadata": {},
   "source": [
    "# IoU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9aae1b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T01:57:32.655170Z",
     "start_time": "2023-07-14T01:57:32.639403Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing (should be better than giou)\n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    "\n",
    "    return iou - ciou_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "92ee4167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:47:52.887742Z",
     "start_time": "2023-07-14T05:47:52.874991Z"
    }
   },
   "outputs": [],
   "source": [
    "def bbox_iou(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    Anchor box 특성 상 중심점이 정해져있기 때문에 w, h 만을 가지고 iou를 계산\n",
    "    \"\"\"\n",
    "    \n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8b7ae",
   "metadata": {},
   "source": [
    "# Anchor + BBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0edd2173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:50:27.818797Z",
     "start_time": "2023-07-14T05:50:27.798755Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_TFRECORD_PATH = \"./EDA/train_dataset.tfrecord\"\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_SIZE = 416\n",
    "scale = 1.1\n",
    "\n",
    "YOLO_ANCHORS = tf.constant([\n",
    "    [[10, 13], [16, 30], [33, 23]],\n",
    "    [[30, 61], [62, 45], [59,119]],\n",
    "    [[116, 90], [156, 198], [373, 326]]\n",
    "], dtype=tf.int32)\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "TRAIN_INPUT_SIZE = 416\n",
    "STRIDES = tf.constant([8, 16, 32],dtype=tf.int32)\n",
    "TRAIN_OUTPUT_SIZE = TRAIN_INPUT_SIZE //STRIDES\n",
    "ANCHOR_PER_SCALE = 3\n",
    "MAX_BBOX_PER_SCALE = 100\n",
    "IOU_ANCHOR_THRESH = 0.3\n",
    "OUTPUT_LEVELS = STRIDES.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6697d4fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:50:28.176277Z",
     "start_time": "2023-07-14T05:50:28.155583Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou_height_width(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = np.concatenate([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = np.concatenate([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "59f3a52c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:55:02.482324Z",
     "start_time": "2023-07-14T05:55:02.397485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[235], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m boxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ [\u001b[38;5;241m101\u001b[39m,\u001b[38;5;241m212\u001b[39m,\u001b[38;5;241m33\u001b[39m,\u001b[38;5;241m43\u001b[39m],[\u001b[38;5;241m142\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m31\u001b[39m,\u001b[38;5;241m61\u001b[39m],[\u001b[38;5;241m311\u001b[39m,\u001b[38;5;241m362\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m41\u001b[39m] ])\n\u001b[0;32m      2\u001b[0m classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpreprocess_true_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[234], line 72\u001b[0m, in \u001b[0;36mpreprocess_true_boxes\u001b[1;34m(bboxes, classes)\u001b[0m\n\u001b[0;32m     69\u001b[0m best_anchor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best_anchor_ind \u001b[38;5;241m%\u001b[39m anchor_per_scale)\n\u001b[0;32m     70\u001b[0m xind, yind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(bbox_xywh_scaled[best_detect, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 72\u001b[0m label[best_detect][yind, xind, best_anchor, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m bbox_xywh\n\u001b[0;32m     73\u001b[0m label[best_detect][yind, xind, best_anchor, \u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     74\u001b[0m label[best_detect][yind, xind, best_anchor, \u001b[38;5;241m5\u001b[39m:] \u001b[38;5;241m=\u001b[39m smooth_onehot\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "boxes = np.array([ [101,212,33,43],[142,21,31,61],[311,362,32,41] ])\n",
    "classes = np.array([0,1,2])\n",
    "\n",
    "preprocess_true_boxes(boxes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "26907dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:55:00.750635Z",
     "start_time": "2023-07-14T05:55:00.729586Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_true_boxes(bboxes, classes):\n",
    "    output_levels = OUTPUT_LEVELS\n",
    "    train_output_sizes = TRAIN_OUTPUT_SIZE\n",
    "    max_bbox_per_scale = MAX_BBOX_PER_SCALE\n",
    "    num_classes = NUM_CLASSES\n",
    "    anchor_per_scale = ANCHOR_PER_SCALE\n",
    "    anchors = YOLO_ANCHORS\n",
    "    iou_anchor_threshold = IOU_ANCHOR_THRESH\n",
    "    strides = STRIDES\n",
    "    \n",
    "    gt_data = np.concatenate( [bboxes, classes[:,np.newaxis]], axis=1)\n",
    "    label = [\n",
    "        np.zeros([52, 52, anchor_per_scale, 5 + num_classes]),\n",
    "        np.zeros([26, 26, anchor_per_scale, 5 + num_classes]),\n",
    "        np.zeros([13, 13, anchor_per_scale, 5 + num_classes])\n",
    "    ]\n",
    "\n",
    "    bboxes_xywh = [\n",
    "        np.zeros((max_bbox_per_scale, 4)),\n",
    "        np.zeros((max_bbox_per_scale, 4)),\n",
    "        np.zeros((max_bbox_per_scale, 4))\n",
    "    ]\n",
    "    \n",
    "    bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
    "\n",
    "    \n",
    "    for bbox in gt_data:\n",
    "        bbox_coor = bbox[:4]\n",
    "        bbox_class_ind =bbox[4]\n",
    "\n",
    "        onehot = np.zeros(num_classes, dtype=np.float32)\n",
    "        onehot[bbox_class_ind] = 1.0\n",
    "        uniform_distribution = np.full(num_classes, 1.0 / num_classes)\n",
    "        deta = 0.01\n",
    "        smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
    "\n",
    "        bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "        bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / strides[:, np.newaxis]\n",
    "\n",
    "        iou = []\n",
    "        exist_positive = False\n",
    "        for i in range(output_levels):#range(3):\n",
    "            anchors_xywh = np.zeros((anchor_per_scale, 4))\n",
    "            anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.float32) + 0.5\n",
    "            anchors_xywh[:, 2:4] = anchors[i]\n",
    "\n",
    "            iou_scale = iou_height_width(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
    "            iou.append(iou_scale)\n",
    "            iou_mask = iou_scale > iou_anchor_threshold\n",
    "\n",
    "            if np.any(iou_mask):\n",
    "                xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.float32)\n",
    "\n",
    "                label[i][yind, xind, iou_mask, :] = 0\n",
    "                label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
    "                label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
    "                label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                bbox_ind = int(bbox_count[i] % max_bbox_per_scale)\n",
    "                bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                bbox_count[i] += 1\n",
    "                exist_positive = True\n",
    "\n",
    "        if not exist_positive:\n",
    "            best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "            best_detect = int(best_anchor_ind / anchor_per_scale)\n",
    "            print(best_detect)\n",
    "            print(type(best_detect))\n",
    "            best_anchor = int(best_anchor_ind % anchor_per_scale)\n",
    "            xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.float32)\n",
    "\n",
    "            label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "            label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "            label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
    "\n",
    "            bbox_ind = int(bbox_count[best_detect] % max_bbox_per_scale)\n",
    "            bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
    "            bbox_count[best_detect] += 1\n",
    "\n",
    "    label_sbbox, label_mbbox, label_lbbox = label\n",
    "#     sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "#     return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "    return label_sbbox, label_mbbox, label_lbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7bd500b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:50:23.876502Z",
     "start_time": "2023-07-14T05:50:23.871577Z"
    }
   },
   "outputs": [],
   "source": [
    "def _process_target(train):\n",
    "    def process_target(gt_boxes, classes):\n",
    "        label_sbbox, label_mbbox, label_lbbox = tf.numpy_function(func=preprocess_true_boxes, inp=[gt_boxes, classes],Tout=[tf.float32, tf.float32, tf.float32])\n",
    "        return label_sbbox, label_mbbox, label_lbbox\n",
    "    return process_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd013f",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7dda427a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:20:57.129303Z",
     "start_time": "2023-07-14T05:20:57.108236Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=int(IMAGE_SIZE * scale)),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(IMAGE_SIZE * scale),\n",
    "            min_width=int(IMAGE_SIZE * scale),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.RandomCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n",
    "        A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n",
    "                ),\n",
    "                A.IAAAffine(shear=15, p=0.5, mode=\"constant\"),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(p=0.1),\n",
    "        A.CLAHE(p=0.1),\n",
    "        A.Posterize(p=0.1),\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ChannelShuffle(p=0.05),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", min_visibility=0.4),\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=IMAGE_SIZE),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\n",
    "        ),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", min_visibility=0.4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc28f2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:20:57.331564Z",
     "start_time": "2023-07-14T05:20:57.314408Z"
    }
   },
   "outputs": [],
   "source": [
    "def aug_fn(image, bbox, train):\n",
    "    data = {\"image\":image,\"bboxes\":bbox}\n",
    "    if train:\n",
    "        aug_data = train_transforms(**data)\n",
    "    else:\n",
    "        aug_data = test_transforms(**data)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_bbox = aug_data[\"bboxes\"]\n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    aug_bbox = tf.cast(aug_bbox, tf.float32)\n",
    "    return aug_img, aug_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28f9f33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:20:57.596504Z",
     "start_time": "2023-07-14T05:20:57.587873Z"
    }
   },
   "outputs": [],
   "source": [
    "def _process_aug(train):\n",
    "    def process_aug(image, bbox):\n",
    "        aug_img, aug_bbox = tf.numpy_function(func=aug_fn, inp=[image, bbox, train],Tout=[tf.float32, tf.float32])\n",
    "        return aug_img, aug_bbox\n",
    "    return process_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e0ee0",
   "metadata": {},
   "source": [
    "# Load TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "46e46894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:21:37.663445Z",
     "start_time": "2023-07-14T05:21:37.644290Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_tfrecord(train):\n",
    "\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {\n",
    "            'filename': tf.io.FixedLenFeature([], tf.string),\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'classes': tf.io.VarLenFeature(tf.int64),\n",
    "#             'objectness': tf.io.VarLenFeature(tf.int64),\n",
    "            'target_id': tf.io.VarLenFeature(tf.int64),\n",
    "            'x_min': tf.io.VarLenFeature(tf.float32),\n",
    "            'y_min': tf.io.VarLenFeature(tf.float32),\n",
    "            'x_max': tf.io.VarLenFeature(tf.float32),\n",
    "            'y_max': tf.io.VarLenFeature(tf.float32),\n",
    "            'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "\n",
    "        parsed_example = tf.io.parse_single_example(tfrecord, features)\n",
    "        img = tf.image.decode_jpeg(parsed_example['image_raw'], channels=3)\n",
    "        \n",
    "        img = tf.cast(img, tf.float32)\n",
    "        width = tf.cast(parsed_example['width'], tf.float32)\n",
    "        height = tf.cast(parsed_example['height'], tf.float32)\n",
    "        \n",
    "        labels = tf.sparse.to_dense(parsed_example['classes'])\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "#         objectness = tf.sparse.to_dense(parsed_example['objectness'])\n",
    "#         objectness = tf.cast(objectness, tf.float32)\n",
    "        target_id = tf.sparse.to_dense(parsed_example['target_id'])\n",
    "        target_id = tf.cast(target_id, tf.float32)\n",
    "        \n",
    "        bboxes = tf.stack(\n",
    "            [\n",
    "                tf.sparse.to_dense(parsed_example['x_min']),\n",
    "                tf.sparse.to_dense(parsed_example['y_min']),\n",
    "                tf.sparse.to_dense(parsed_example['x_max']),\n",
    "                tf.sparse.to_dense(parsed_example['y_max']),\n",
    "            ],axis=1)\n",
    "        \n",
    "        img, bboxes = _process_aug(train)(img, bboxes)\n",
    "          \n",
    "        label_sbbox, label_mbbox, label_lbbox = _process_target(train)(bboxes, labels)\n",
    "        \n",
    "        img.set_shape( (416,416,3) )\n",
    "#         label_sbbox.set_shape ((416,416,3))\n",
    "#         label_mbbox.set_shape ((416,416,3))\n",
    "#         label_lbbox.set_shape ((416,416,3))\n",
    "        return img,  label_sbbox, label_mbbox, label_lbbox\n",
    "\n",
    "    return parse_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "eea6a27b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:21:32.868144Z",
     "start_time": "2023-07-14T05:21:32.857457Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tfrecord_dataset(tfrecord_name, train=True, buffer_size=1024):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.cache() # 처음 불러오게 되면 캐시메모리로 저장\n",
    "    \n",
    "    if train:\n",
    "        raw_dataset = raw_dataset.repeat() # 이 데이터를 몇번 iteration할건지 지정, 지정하지 않으면 -1로 되며 계속 반복\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size) # 데이터 셔플\n",
    "        \n",
    "    # 데이터 읽기 시작\n",
    "    raw_dataset = raw_dataset.map(_parse_tfrecord(train), num_parallel_calls=tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "    raw_dataset = raw_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    raw_dataset = raw_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2bc58",
   "metadata": {},
   "source": [
    "# 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "63e6f20c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:21:33.567570Z",
     "start_time": "2023-07-14T05:21:33.347033Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_tfrecord_dataset(\n",
    "    tfrecord_name=TRAIN_TFRECORD_PATH,\n",
    "    train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9e76b138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T05:25:48.638517Z",
     "start_time": "2023-07-14T05:25:48.262816Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: filename (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} Feature: filename (data type: string) is required but could not be found.\n\t [[{{node ParseSingleExample/ParseExample/ParseExampleV2}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba4e5a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T08:34:23.095680Z",
     "start_time": "2023-07-13T08:34:23.081219Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(boxes, train=True, buffer_size=1024):\n",
    "    if train:\n",
    "        dataset = load_tfrecord_dataset(\n",
    "            tfrecord_name=TRAIN_TFRECORD_PATH,\n",
    "            train=train,\n",
    "            boxes=boxes,\n",
    "            buffer_size=buffer_size)\n",
    "    else:\n",
    "        dataset = load_tfrecord_dataset(\n",
    "            tfrecord_name=VALID_TFRECORD_PATH,\n",
    "            train=train,\n",
    "            boxes=boxes,\n",
    "            buffer_size=buffer_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "287c18e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T15:44:00.264235Z",
     "start_time": "2023-07-12T15:44:00.249028Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d69ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fbf94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
