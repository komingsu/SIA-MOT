{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd97de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_timing' from '_timing' (d:\\PROJECT\\Metric\\_timing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimize\u001b[39;00m \u001b[39mimport\u001b[39;00m linear_sum_assignment \u001b[39m# 선형 할당 문제를 풀기 위한 라이브러리(Linear Assignment Problem)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m_base_metric\u001b[39;00m \u001b[39mimport\u001b[39;00m _BaseMetric\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m_timing\u001b[39;00m \u001b[39mimport\u001b[39;00m _timing\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n",
      "File \u001b[1;32md:\\PROJECT\\Metric\\_base_metric.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabc\u001b[39;00m \u001b[39mimport\u001b[39;00m ABC, abstractmethod\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport\u001b[39;00m _timing\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m TrackEvalException\n\u001b[0;32m      7\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_BaseMetric\u001b[39;00m(ABC):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_timing' from '_timing' (d:\\PROJECT\\Metric\\_timing.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment # 선형 할당 문제를 풀기 위한 라이브러리(Linear Assignment Problem)\n",
    "from _base_metric import _BaseMetric\n",
    "from _timing import _timing\n",
    "from utils import utils\n",
    "\n",
    "class CLEAR(_BaseMetric): # _BaseMetric를 상속하는 class(지표에 대한 기본 클래스)\n",
    "    \"\"\"Class which implements the CLEAR metrics\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config(): # 지표의 기본 구성 값이 포함된 딕셔너리를 반환\n",
    "        \"\"\"Default class config values\"\"\"\n",
    "        default_config = {\n",
    "            'THRESHOLD': 0.5,  # True Positive에 대한 threshold\n",
    "            'PRINT_CONFIG': True,  # Whether to print the config information on init. Default: False.\n",
    "        }\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, config=None): # CLEAR 객체를 초기화\n",
    "        super().__init__()\n",
    "        main_integer_fields = ['CLR_TP', 'CLR_FN', 'CLR_FP', 'IDSW', 'MT', 'PT', 'ML', 'Frag']\n",
    "        # CLR_TP - True Positive(올바르게 매칭된 추적 결과의 수)\n",
    "        # CLR_FN - False Negative(매칭되지 않은 실제 객체의 수)\n",
    "        # CLR_FP - False Positive(잘못 매칭된 추적 결과의 수)\n",
    "        # MT(Most Tracked) - 대부분의 시간 동안 정확히 추적된 객체의 수\n",
    "        # PT(Partially Tracked) - 일부 시간 동안 추적된 객체의 수\n",
    "        # ML(Mostly Lost) - 대부분의 시간 동안 추적을 실패한 객체의 수\n",
    "        # Frag(Fragments) - 중간에 끊어진 추적 경로의 개수\n",
    "        \n",
    "        extra_integer_fields = ['CLR_Frames']\n",
    "        # CLR_Frames - 평가 대상 시퀀스의 프레임 수\n",
    "        \n",
    "        self.integer_fields = main_integer_fields + extra_integer_fields\n",
    "        \n",
    "        main_float_fields = ['MOTA', 'MOTP', 'MODA', 'CLR_Re', 'CLR_Pr', 'MTR', 'PTR', 'MLR', 'sMOTA'] # 주요 부동 소수점 필드 목록\n",
    "        # MOTA(Multiple Object Tracking Accuracy) - 다중 객체 추적 정확도\n",
    "        # MOTP (Multiple Object Tracking Precision) - 다중 객체 추정 정밀도\n",
    "        # MODA (Multiple Object Detection Accuracy) - 다둥 객체 감지 정확도\n",
    "        # CLR_Re (CLEAR Recall) - CLEAR 재현율\n",
    "        # CLR_Pr (CLEAR Precision) - CLEAR 정밀도\n",
    "        # MTR (Multiple Object Tracking Ratio) - 다중 객체 추적 비율\n",
    "        # PTR (Partial Tracking Ratio) - 부분 추적 비율\n",
    "        # MLR (Mostly Lost Ratio) - 대부분 손실 비율\n",
    "        # sMOTA (Scaled MOTA) - 조정된 MOTA\n",
    "        \n",
    "        extra_float_fields = ['CLR_F1', 'FP_per_frame', 'MOTAL', 'MOTP_sum'] # 추가 부동 소수점 필드 목록\n",
    "        # CLR_F1 (CLEAR F1 Score) - CLEAR F1 점수\n",
    "        # FP_per_frame (False Positives per Frame) - 프레임 당 거짓 양성 수\n",
    "        # MOTAL (Multiple Object Tracking Accuracy with Log) - 로그를 적용한 다중 객체 추적 정확도\n",
    "        # MOTP_sum (Sum of MOTP) - MOTP의 합계\n",
    "    \n",
    "        self.float_fields = main_float_fields + extra_float_fields\n",
    "        self.fields = self.float_fields + self.integer_fields\n",
    "        \n",
    "        self.summed_fields = self.integer_fields + ['MOTP_sum']\n",
    "        self.summary_fields = main_float_fields + main_integer_fields\n",
    "\n",
    "        # Configuration options:\n",
    "        self.config = utils.init_config(config, self.get_default_config(), self.get_name())\n",
    "        self.threshold = float(self.config['THRESHOLD'])\n",
    "\n",
    "\n",
    "    @_timing.time\n",
    "    def eval_sequence(self, data): # 단일 시퀀스에 대한 CLEAR 지표를 계산\n",
    "        \"\"\"Calculates CLEAR metrics for one sequence\"\"\"\n",
    "        \n",
    "        # data -> groundtruth와 예측된 객체 추적에 대한 정보\n",
    "        \n",
    "        # result 초기화\n",
    "        res = {}\n",
    "        for field in self.fields:\n",
    "            res[field] = 0\n",
    "\n",
    "        # tracker나 gt sentence가 비었으면 result를 즉시 return\n",
    "        if data['num_tracker_dets'] == 0:\n",
    "            res['CLR_FN'] = data['num_gt_dets']\n",
    "            res['ML'] = data['num_gt_ids']\n",
    "            res['MLR'] = 1.0\n",
    "            return res\n",
    "        \n",
    "        if data['num_gt_dets'] == 0:\n",
    "            res['CLR_FP'] = data['num_tracker_dets']\n",
    "            res['MLR'] = 1.0\n",
    "            return res\n",
    "\n",
    "        # 전역 연관 관련 변수를 초기화\n",
    "        num_gt_ids = data['num_gt_ids'] # Ground Truth 식별자의 총 수\n",
    "        \n",
    "        gt_id_count = np.zeros(num_gt_ids)  # 관심 대상 식별자별로 MT, ML, PT 계산을 위한 배열\n",
    "                                            # 얼마나 개별 관심 대상 식별자를 얼마나 잘 추적했는지, \n",
    "                                            # 얼마나 많은 프레임에서 추적되었는지, \n",
    "                                            # 얼마나 많은 프레임에서 손실되었는지 추적하는데 사용\n",
    "                                            \n",
    "        gt_matched_count = np.zeros(num_gt_ids)  # 관심 대상 식별자별로 MT, ML, PT 계산을 위한 배열\n",
    "                                                 # 실제로 추적된 관심 대상 식별자의 수를 추적하는데 사용\n",
    "                                                 \n",
    "        gt_frag_count = np.zeros(num_gt_ids)  # 관심 대상 식별자별로 Frag(Fragmentation) 계산하기 위한 배열\n",
    "                                              # 얼마나 많은 프레임에서 손실되었다가 다시 추적되는 관심 대상 식별자를 추적하는데 사용\n",
    "\n",
    "        # Note that IDSWs are counted based on the last time each gt_id was present (any number of frames previously),\n",
    "        # 각 gt_id가 이전에 언제 존재했는지(이전의 임의의 프레임 수에 걸쳐)에 따라 IDSW(Identity Switch)가 계산\n",
    "        # but are only used in matching to continue current tracks based on the gt_id in the single previous timestep.\n",
    "        # 그러나 IDSW는 매칭에만 사용되며, 현재 트랙을 이전 단일 시간 단계의 gt_id를 기반으로 유지하기 위해 사용\n",
    "        \n",
    "        prev_tracker_id = np.nan * np.zeros(num_gt_ids)  # IDSW 계산을 위한 배열\n",
    "        prev_timestep_tracker_id = np.nan * np.zeros(num_gt_ids)  # 각 gt_id에 대해 이전 시간 단계에서 매칭되었던 tracker_id를 기록(없는 경우 NaN)\n",
    "\n",
    "        # 타임스팀프에 대한 각각의 점수 계산\n",
    "        for t, (gt_ids_t, tracker_ids_t) in enumerate(zip(data['gt_ids'], data['tracker_ids'])):\n",
    "            # Deal with the case that there are no gt_det/tracker_det in a timestep.\n",
    "            # gt_det 또는 tracker_det이 특정 타임스탬프에 없는 경우를 처리\n",
    "            # gt_ids_t -> 해당 시간 단계에서의 ground truth detection의 식별자(ID)\n",
    "            \n",
    "            # FP 계산\n",
    "            \n",
    "            if len(gt_ids_t) == 0: \n",
    "                res['CLR_FP'] += len(tracker_ids_t)\n",
    "                continue\n",
    "            \n",
    "            # FN 계산\n",
    "            if len(tracker_ids_t) == 0:\n",
    "                res['CLR_FN'] += len(gt_ids_t)\n",
    "                gt_id_count[gt_ids_t] += 1\n",
    "                continue\n",
    "\n",
    "            # Calc score matrix to first minimise IDSWs from previous frame, and then maximise MOTP secondarily\n",
    "            # 이전 프레임에서 IDSW(ID Switches)를 최소화하기 위해 점수 행렬을 계산하고, 그 다음으로 MOTP(Mean Overlap Ratio of True Positives)를 최대화하기 위해 계산\n",
    "            \n",
    "            similarity = data['similarity_scores'][t]\n",
    "            \n",
    "            # score_mat -> 점수 행렬\n",
    "            \n",
    "            score_mat = (tracker_ids_t[np.newaxis, :] == prev_timestep_tracker_id[gt_ids_t[:, np.newaxis]])\n",
    "            score_mat = 1000 * score_mat + similarity\n",
    "            score_mat[similarity < self.threshold - np.finfo('float').eps] = 0\n",
    "\n",
    "            # Hungarian algorithm to find best matches\n",
    "            # 헝가리안 알고리즘 사용\n",
    "            \n",
    "            match_rows, match_cols = linear_sum_assignment(-score_mat)\n",
    "            actually_matched_mask = score_mat[match_rows, match_cols] > 0 + np.finfo('float').eps\n",
    "            match_rows = match_rows[actually_matched_mask]\n",
    "            match_cols = match_cols[actually_matched_mask]\n",
    "\n",
    "            matched_gt_ids = gt_ids_t[match_rows]\n",
    "            matched_tracker_ids = tracker_ids_t[match_cols]\n",
    "\n",
    "            # Calc IDSW for MOTA\n",
    "            # MOTA에 쓰일 IDSW 계산\n",
    "            \n",
    "            prev_matched_tracker_ids = prev_tracker_id[matched_gt_ids]\n",
    "            is_idsw = (np.logical_not(np.isnan(prev_matched_tracker_ids))) & (\n",
    "                np.not_equal(matched_tracker_ids, prev_matched_tracker_ids))\n",
    "            res['IDSW'] += np.sum(is_idsw)\n",
    "\n",
    "            # Update counters for MT/ML/PT/Frag and record for IDSW/Frag for next timestep\n",
    "            # 다음 타임스탬프를 위해 MT/ML/PT/Frag 및 IDSW/Frag을(를) 업데이트하고 기록\n",
    "            \n",
    "            gt_id_count[gt_ids_t] += 1\n",
    "            gt_matched_count[matched_gt_ids] += 1\n",
    "            not_previously_tracked = np.isnan(prev_timestep_tracker_id)\n",
    "            prev_tracker_id[matched_gt_ids] = matched_tracker_ids\n",
    "            prev_timestep_tracker_id[:] = np.nan\n",
    "            prev_timestep_tracker_id[matched_gt_ids] = matched_tracker_ids\n",
    "            currently_tracked = np.logical_not(np.isnan(prev_timestep_tracker_id))\n",
    "            gt_frag_count += np.logical_and(not_previously_tracked, currently_tracked)\n",
    "\n",
    "            # Calculate and accumulate basic statistics\n",
    "            # 기본 통계를 계산하고 누적\n",
    "            \n",
    "            num_matches = len(matched_gt_ids)\n",
    "            res['CLR_TP'] += num_matches\n",
    "            res['CLR_FN'] += len(gt_ids_t) - num_matches\n",
    "            res['CLR_FP'] += len(tracker_ids_t) - num_matches\n",
    "            if num_matches > 0:\n",
    "                res['MOTP_sum'] += sum(similarity[match_rows, match_cols])\n",
    "\n",
    "        # Calculate MT/ML/PT/Frag/MOTP\n",
    "        # MT/ML/PT/Frag/MOTP 계산\n",
    "        tracked_ratio = gt_matched_count[gt_id_count > 0] / gt_id_count[gt_id_count > 0]\n",
    "        res['MT'] = np.sum(np.greater(tracked_ratio, 0.8))\n",
    "        res['PT'] = np.sum(np.greater_equal(tracked_ratio, 0.2)) - res['MT']\n",
    "        res['ML'] = num_gt_ids - res['MT'] - res['PT']\n",
    "        res['Frag'] = np.sum(np.subtract(gt_frag_count[gt_frag_count > 0], 1))\n",
    "        res['MOTP'] = res['MOTP_sum'] / np.maximum(1.0, res['CLR_TP'])\n",
    "\n",
    "        res['CLR_Frames'] = data['num_timesteps']\n",
    "\n",
    "        # Calculate final CLEAR scores\n",
    "        # 최종 CLEAR 점수 계산\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "    \n",
    "    # 모든 시퀀스에 대해 Metrics를 결합\n",
    "    # input : all_res(딕셔너리) - 각 시퀀스에 대한 Metrics\n",
    "    # 모든 시퀀스에 대한 metrics)를 결합하여 하나의 결과를 생성\n",
    "\n",
    "    def combine_sequences(self, all_res):\n",
    "        \"\"\"Combines metrics across all sequences\"\"\"\n",
    "        res = {}\n",
    "        for field in self.summed_fields:\n",
    "            res[field] = self._combine_sum(all_res, field)\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "    \n",
    "    # 모든 클래스에 대해 Metrics를 결합\n",
    "    # input : all_res(딕셔너리) - 각 클래스에 대한 Metrics\n",
    "    # 각 클래스에 대한 metrics를 결합하여 하나의 결과를 생성\n",
    "\n",
    "    def combine_classes_det_averaged(self, all_res):\n",
    "        \"\"\"Combines metrics across all classes by averaging over the detection values\"\"\"\n",
    "        res = {}\n",
    "        for field in self.summed_fields:\n",
    "            res[field] = self._combine_sum(all_res, field)\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "    \n",
    "    #  모든 클래스에 대해 Metrics를 결합\n",
    "    # input : all_res(딕셔너리), ignore_empty_classes(bool값)\n",
    "\n",
    "    def combine_classes_class_averaged(self, all_res, ignore_empty_classes=False):\n",
    "        \"\"\"Combines metrics across all classes by averaging over the class values.\n",
    "        If 'ignore_empty_classes' is True, then it only sums over classes with at least one gt or predicted detection.\n",
    "        \"\"\"\n",
    "        res = {}\n",
    "        # 1. 정수 필드\n",
    "        for field in self.integer_fields:\n",
    "            \n",
    "            # 빈 클래스를 무시할 경우\n",
    "            # 적어도 하나의 ground truth 또는 예측된 detection이 있는 클래스만을 고려하여 값을 합산\n",
    "            # all_res에서 CLR_TP, CLR_FN, CLR_FP 중 하나라도 값이 0보다 큰 클래스들만 선택하여 처리\n",
    "            if ignore_empty_classes:\n",
    "                res[field] = self._combine_sum(\n",
    "                    {k: v for k, v in all_res.items() if v['CLR_TP'] + v['CLR_FN'] + v['CLR_FP'] > 0}, field)\n",
    "                \n",
    "            # 빈 클래스를 무시하지 않을 경우\n",
    "            # 모든 값을 합산\n",
    "            else:\n",
    "                res[field] = self._combine_sum({k: v for k, v in all_res.items()}, field)\n",
    "        \n",
    "        # 2. 실수 필드        \n",
    "        for field in self.float_fields:\n",
    "            \n",
    "            # 빈 클래스를 무시할 경우\n",
    "            # 적어도 하나의 ground truth 또는 예측된 detection이 있는 클래스만을 고려하여 값을 합산\n",
    "            # all_res에서 CLR_TP, CLR_FN, CLR_FP 중 하나라도 값이 0보다 큰 클래스들만 선택하여 처리\n",
    "            if ignore_empty_classes:\n",
    "                res[field] = np.mean(\n",
    "                    [v[field] for v in all_res.values() if v['CLR_TP'] + v['CLR_FN'] + v['CLR_FP'] > 0], axis=0)\n",
    "                \n",
    "            # 빈 클래스를 무시하지 않을 경우\n",
    "            # 모든 값을 합산\n",
    "            else:\n",
    "                res[field] = np.mean([v[field] for v in all_res.values()], axis=0)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_final_fields(res):\n",
    "        \"\"\"Calculate sub-metric ('field') values which only depend on other sub-metric values.\n",
    "        This function is used both for both per-sequence calculation, and in combining values across sequences.\n",
    "        \"\"\"\n",
    "        num_gt_ids = res['MT'] + res['ML'] + res['PT']\n",
    "        res['MTR'] = res['MT'] / np.maximum(1.0, num_gt_ids)\n",
    "        res['MLR'] = res['ML'] / np.maximum(1.0, num_gt_ids)\n",
    "        res['PTR'] = res['PT'] / np.maximum(1.0, num_gt_ids)\n",
    "        res['CLR_Re'] = res['CLR_TP'] / np.maximum(1.0, res['CLR_TP'] + res['CLR_FN'])\n",
    "        res['CLR_Pr'] = res['CLR_TP'] / np.maximum(1.0, res['CLR_TP'] + res['CLR_FP'])\n",
    "        res['MODA'] = (res['CLR_TP'] - res['CLR_FP']) / np.maximum(1.0, res['CLR_TP'] + res['CLR_FN'])\n",
    "        res['MOTA'] = (res['CLR_TP'] - res['CLR_FP'] - res['IDSW']) / np.maximum(1.0, res['CLR_TP'] + res['CLR_FN'])\n",
    "        res['MOTP'] = res['MOTP_sum'] / np.maximum(1.0, res['CLR_TP'])\n",
    "        res['sMOTA'] = (res['MOTP_sum'] - res['CLR_FP'] - res['IDSW']) / np.maximum(1.0, res['CLR_TP'] + res['CLR_FN'])\n",
    "\n",
    "        res['CLR_F1'] = res['CLR_TP'] / np.maximum(1.0, res['CLR_TP'] + 0.5*res['CLR_FN'] + 0.5*res['CLR_FP'])\n",
    "        res['FP_per_frame'] = res['CLR_FP'] / np.maximum(1.0, res['CLR_Frames'])\n",
    "        safe_log_idsw = np.log10(res['IDSW']) if res['IDSW'] > 0 else res['IDSW']\n",
    "        res['MOTAL'] = (res['CLR_TP'] - res['CLR_FP'] - safe_log_idsw) / np.maximum(1.0, res['CLR_TP'] + res['CLR_FN'])\n",
    "        return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d9644de",
   "metadata": {},
   "source": [
    "### scipy.optimize.linear_sum_assignment\n",
    "\n",
    "- 선형 할당 문제(Linear Assignment Problem)를 풀기 위한 함수\n",
    "- 선형 할당 문제는 일반적으로 비용 행렬 또는 유사도 행렬이 주어지며, 첫 번째 집합의 요소를 두 번째 집합의 요소와 매핑시키는 방식으로 해결\n",
    "- 헝가리안 알고리즘(Hungarian algorithm)을 사용하여 선형 할당 문제를 해결\n",
    "- 시간 복잡도가 O(n^3)이며, 일반적으로 작은 크기의 할당 문제에 사용\n",
    "\n",
    "- 인수\n",
    "    - cost_matrix : 비용 행렬 또는 유사도 행렬로, 첫 번째 집합과 두 번째 집합 간의 비용 또는 유사도를 나타냅니다. 일반적으로 NxM 크기의 2D 배열로 표현\n",
    "    - method : 헝가리안 알고리즘의 최적화 방법을 선택합니다. 기본값은 \"auction\"이며, 다른 옵션으로 \"path\"와 \"dense\n",
    "\n",
    "- 최적의 매칭을 나타내는 두 개의 배열을 반환\n",
    "    - row_ind : 첫 번째 집합의 요소와 매칭된 두 번째 집합의 요소의 인덱스 배열\n",
    "    - col_ind : 두 번째 집합의 요소와 매칭된 첫 번째 집합의 요소의 인덱스 배열"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3071f84d",
   "metadata": {},
   "source": [
    "###  ._base_metric._BaseMetric\n",
    "\n",
    "- CLEAR 클래스에서 상속한 _BaseMetric이라는 모듈\n",
    "- CLEAR 클래스의 기본 지표 클래스로 사용되며, 지표 계산에 필요한 공통 기능과 구조를 정의\n",
    "\n",
    "- 기능\n",
    "    - get_name : 지표의 이름을 반환(하위 클래스에서 구현되어야함)\n",
    "    - get_fields : 지표에서 반환되는 필드(메트릭)의 이름 목록을 반환(하위 클래스에서 구현되어야함)\n",
    "    - eval_sequence : 하위 클래스에서 구현되어야 하는 메서드로, 단일 시퀀스에 대한 지표를 계산, 시퀀스에 대한 입력 데이터를 받아 필요한 계산을 수행하고, 결과를 딕셔너리 형태로 반환\n",
    "    - combine_sequences : 모든 시퀀스의 지표를 결합하여 전체 시퀀스에 대한 종합 지표를 계산하는 메서드입니다. 단일 시퀀스 결과의 리스트를 입력으로 받아 필요한 필드를 합산하여 결과를 반환"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7419dc87",
   "metadata": {},
   "source": [
    "### INPUT이 될 - data(배열)가 가져야할 정보\n",
    "- num_tracker_dets: 추적기에서 감지한 객체의 수\n",
    "- num_gt_dets: 실제 객체의 수\n",
    "- gt_ids: 각 타임스텝에서의 실제 객체의 식별자(ID) 배열\n",
    "- tracker_ids: 각 타임스텝에서 추적기가 예측한 객체의 식별자(ID) 배열\n",
    "- similarity_scores: 타임스텝별 유사도 점수 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 적용 예시코드\n",
    "# 데이터셋에서 필요한 정보를 추출하여 data 배열을 생성\n",
    "data = {\n",
    "    'num_tracker_dets': num_tracker_dets, # tracker로 생성된 tracking 결과의 총 개수(스칼라)\n",
    "    'num_gt_dets': num_gt_dets, # 실제 ground truth의 총 개수(스칼라)\n",
    "    'gt_ids': gt_ids, # 각 타임스탬프 별 실제 ground truth의 ID를 나타내는 배열 - 크기(타임스탬프 수, 실제 객체 수)\n",
    "    # EX) [[1, 2], [3, 4]] -> 첫 번째 타임스탬프에는 1, 2번 객체가 존재 두 번째 타임스탬프에는 3, 4번 객체가 존재  \n",
    "    'tracker_ids': tracker_ids, # 각 타임스탬프 별 tracker에 의해 생성된 추적 결과의 ID를 나타내는 배열 - 크기(타임스탬프 수, 추적 결과 수)\n",
    "    # EX) [[1, 3, 5], [2, 4, 6]] -> 첫 번째 타임스탬프에는 1, 3, 5번 객체가 tracking, 두 번째 타임스탬프에는 2, 4, 6번 객체가 tracking\n",
    "    'similarity_scores': similarity_scores # 유사도 배열 - 크기(타임스탬프 수, 추적 결과 수, 실제 객체 수)\n",
    "    # EX) [[[0.8, 0.5, 0.2], [0.6, 0.4, 0.1]], [[0.7, 0.3, 0.6], [0.9, 0.2, 0.4]]]\n",
    "    # 첫 번째 시간 단계\n",
    "    # 추적된 객체 1과 실제 객체 1의 유사도 점수: 0.8\n",
    "    # 추적된 객체 1과 실제 객체 2의 유사도 점수: 0.5\n",
    "    # 추적된 객체 1과 실제 객체 3의 유사도 점수: 0.2\n",
    "    # 추적된 객체 2과 실제 객체 1의 유사도 점수: 0.6\n",
    "    # 추적된 객체 2과 실제 객체 2의 유사도 점수: 0.4\n",
    "    # 추적된 객체 2과 실제 객체 3의 유사도 점수: 0.1\n",
    "    # 두 번째 시간 단계\n",
    "    # 추적된 객체 1과 실제 객체 1의 유사도 점수: 0.7\n",
    "    # 추적된 객체 1과 실제 객체 2의 유사도 점수: 0.3\n",
    "    # 추적된 객체 1과 실제 객체 3의 유사도 점수: 0.6\n",
    "    # 추적된 객체 2과 실제 객체 1의 유사도 점수: 0.9\n",
    "    # 추적된 객체 2과 실제 객체 2의 유사도 점수: 0.2\n",
    "    # 추적된 객체 2과 실제 객체 3의 유사도 점수: 0.4\n",
    "}\n",
    "\n",
    "# CLEAR 객체 생성\n",
    "clear = CLEAR()\n",
    "\n",
    "# eval_sequence 메서드를 사용하여 MOTA 계산\n",
    "mota = clear.eval_sequence(data)['MOTA']\n",
    "\n",
    "# MOTA 출력\n",
    "print(f\"MOTA: {mota}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b128214",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "- https://visailabs.com/evaluating-multiple-object-tracking-accuracy-and-performance-metrics-in-a-real-time-setting/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03778dd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
