{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from ._base_metric import _BaseMetric\n",
    "from .. import _timing\n",
    "from .. import utils\n",
    "\n",
    "\n",
    "class Identity(_BaseMetric):\n",
    "    \"\"\"Class which implements the ID metrics\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        \"\"\"Default class config values\"\"\"\n",
    "        default_config = {\n",
    "            'THRESHOLD': 0.5,  # Similarity score threshold required for a IDTP match. Default 0.5.\n",
    "            'PRINT_CONFIG': True,  # Whether to print the config information on init. Default: False.\n",
    "        }\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        self.integer_fields = ['IDTP', 'IDFN', 'IDFP'] # 정수 Field - TP, FN, FP\n",
    "        self.float_fields = ['IDF1', 'IDR', 'IDP'] # 실수 Field - IDF1, IDR, IDP\n",
    "        self.fields = self.float_fields + self.integer_fields\n",
    "        self.summary_fields = self.fields\n",
    "\n",
    "        # Configuration options:\n",
    "        self.config = utils.init_config(config, self.get_default_config(), self.get_name())\n",
    "        self.threshold = float(self.config['THRESHOLD'])\n",
    "        \n",
    "    # 단일 시퀀스에 대한 Identity 지표 계산\n",
    "    @_timing.time\n",
    "    def eval_sequence(self, data):\n",
    "        \"\"\"Calculates ID metrics for one sequence\"\"\"\n",
    "        # 초기화\n",
    "        res = {}\n",
    "        for field in self.fields:\n",
    "            res[field] = 0\n",
    "            \n",
    "        # tracker 비었으면 result 즉시 return\n",
    "        if data['num_tracker_dets'] == 0:\n",
    "            res['IDFN'] = data['num_gt_dets']\n",
    "            return res\n",
    "        \n",
    "        # ground truth 시퀀스가 비었으면 result 즉시 return\n",
    "        if data['num_gt_dets'] == 0:\n",
    "            res['IDFP'] = data['num_tracker_dets']\n",
    "            return res\n",
    "\n",
    "        # 카운팅을 위한 글로벌 변수\n",
    "        \n",
    "        # potential_matches_count -> 적된 객체와 실제 객체 간의 잠재적 매칭 횟수를 추적\n",
    "        # data['num_gt_ids'] -> 실제 객체의 개수\n",
    "        # data['num_tracker_ids'] -> 추적된 객체의 개수\n",
    "        potential_matches_count = np.zeros((data['num_gt_ids'], data['num_tracker_ids']))\n",
    "        \n",
    "        # gt_id_count -> 실제 객체의 detection 수를 추적(실제 객체의 탐지 수)\n",
    "        gt_id_count = np.zeros(data['num_gt_ids'])\n",
    "        \n",
    "        # tracker_id_count -> 추적된 객체의 탐지 수를 추적\n",
    "        tracker_id_count = np.zeros(data['num_tracker_ids'])\n",
    "\n",
    "        # First loop through each timestep and accumulate global track information.\n",
    "        # 각 타임스텝을 처음부터 반복하며 전역 추적 정보를 누적\n",
    "        for t, (gt_ids_t, tracker_ids_t) in enumerate(zip(data['gt_ids'], data['tracker_ids'])):\n",
    "            # Count the potential matches between ids in each timestep\n",
    "            # 타임스탬프 별로 매칭 카운팅\n",
    "            # np.greater_equal -> threshold보다 큰 경우 True 작은 경우 False\n",
    "            matches_mask = np.greater_equal(data['similarity_scores'][t], self.threshold) # threshold 이상인 매칭 찾기용 마스크\n",
    "            # threshold 이상인 실제 객체의 인덱스, 추적된 객체의 인덱스\n",
    "            match_idx_gt, match_idx_tracker = np.nonzero(matches_mask)\n",
    "            \n",
    "            # 실제 객체와 탐지 대상 객체가 일치하면 + 1\n",
    "            potential_matches_count[gt_ids_t[match_idx_gt], tracker_ids_t[match_idx_tracker]] += 1\n",
    "\n",
    "            # Calculate the total number of dets for each gt_id and tracker_id.\n",
    "            gt_id_count[gt_ids_t] += 1 # 실제 객체의 탐지 수 + 1\n",
    "            tracker_id_count[tracker_ids_t] += 1 # 추적된 객체의 탐지 수 + 1\n",
    "\n",
    "        # Calculate optimal assignment cost matrix for ID metrics\n",
    "        # ID 지표를 위한 최적 할당 비용 행렬을 계산\n",
    "        \n",
    "        # 유사도가 높으면 매칭 비용이 낮아짐\n",
    "        # 유사도가 낮으면 매칭 비용이 높아짐\n",
    "        num_gt_ids = data['num_gt_ids']\n",
    "        num_tracker_ids = data['num_tracker_ids']\n",
    "        # False Positive\n",
    "        fp_mat = np.zeros((num_gt_ids + num_tracker_ids, num_gt_ids + num_tracker_ids))\n",
    "        # False Negative\n",
    "        fn_mat = np.zeros((num_gt_ids + num_tracker_ids, num_gt_ids + num_tracker_ids))\n",
    "        fp_mat[num_gt_ids:, :num_tracker_ids] = 1e10 # 행렬의 좌측 하단 부분에 매우 큰 값 할당(이 영역의 매칭이 불가능하게)\n",
    "        fn_mat[:num_gt_ids, num_tracker_ids:] = 1e10 # 행렬의 우측 상단 부분에 매우 큰 값 할당(이 영역의 매칭이 불가능하게)\n",
    "        # 매우 큰 값을 할당하는 대신 gt_id_count 값을 할당(실제 객체의 누락에 대한 할당 비용이 증가, 실제 객체의 매칭을 정리하고 누락을 패널티로 간주)\n",
    "        for gt_id in range(num_gt_ids):\n",
    "            fn_mat[gt_id, :num_tracker_ids] = gt_id_count[gt_id]\n",
    "            fn_mat[gt_id, num_tracker_ids + gt_id] = gt_id_count[gt_id]\n",
    "            \n",
    "        # 매우 큰 값을 할당하는 대신 gt_id_count 값을 할당\n",
    "        for tracker_id in range(num_tracker_ids):\n",
    "            fp_mat[:num_gt_ids, tracker_id] = tracker_id_count[tracker_id]\n",
    "            fp_mat[tracker_id + num_gt_ids, tracker_id] = tracker_id_count[tracker_id]\n",
    "        fn_mat[:num_gt_ids, :num_tracker_ids] -= potential_matches_count\n",
    "        fp_mat[:num_gt_ids, :num_tracker_ids] -= potential_matches_count\n",
    "\n",
    "        # Hungarian algorithm\n",
    "        # 헝가리안 알고리즘\n",
    "        match_rows, match_cols = linear_sum_assignment(fn_mat + fp_mat)\n",
    "\n",
    "        # Accumulate basic statistics\n",
    "        # IDFN, IDFP, IDTP 계산\n",
    "        res['IDFN'] = fn_mat[match_rows, match_cols].sum().astype(np.int)\n",
    "        res['IDFP'] = fp_mat[match_rows, match_cols].sum().astype(np.int)\n",
    "        res['IDTP'] = (gt_id_count.sum() - res['IDFN']).astype(np.int)\n",
    "\n",
    "        # Calculate final ID scores\n",
    "        # 최종적인 ID 지표 계산\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "\n",
    "    def combine_classes_class_averaged(self, all_res, ignore_empty_classes=False):\n",
    "        \"\"\"Combines metrics across all classes by averaging over the class values.\n",
    "        If 'ignore_empty_classes' is True, then it only sums over classes with at least one gt or predicted detection.\n",
    "        \"\"\"\n",
    "        res = {}\n",
    "        for field in self.integer_fields:\n",
    "            if ignore_empty_classes:\n",
    "                res[field] = self._combine_sum({k: v for k, v in all_res.items()\n",
    "                                                if v['IDTP'] + v['IDFN'] + v['IDFP'] > 0 + np.finfo('float').eps},\n",
    "                                               field)\n",
    "            else:\n",
    "                res[field] = self._combine_sum({k: v for k, v in all_res.items()}, field)\n",
    "        for field in self.float_fields:\n",
    "            if ignore_empty_classes:\n",
    "                res[field] = np.mean([v[field] for v in all_res.values()\n",
    "                                      if v['IDTP'] + v['IDFN'] + v['IDFP'] > 0 + np.finfo('float').eps], axis=0)\n",
    "            else:\n",
    "                res[field] = np.mean([v[field] for v in all_res.values()], axis=0)\n",
    "        return res\n",
    "\n",
    "    def combine_classes_det_averaged(self, all_res):\n",
    "        \"\"\"Combines metrics across all classes by averaging over the detection values\"\"\"\n",
    "        res = {}\n",
    "        for field in self.integer_fields:\n",
    "            res[field] = self._combine_sum(all_res, field)\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "\n",
    "    def combine_sequences(self, all_res):\n",
    "        \"\"\"Combines metrics across all sequences\"\"\"\n",
    "        res = {}\n",
    "        for field in self.integer_fields:\n",
    "            res[field] = self._combine_sum(all_res, field)\n",
    "        res = self._compute_final_fields(res)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_final_fields(res):\n",
    "        \"\"\"Calculate sub-metric ('field') values which only depend on other sub-metric values.\n",
    "        This function is used both for both per-sequence calculation, and in combining values across sequences.\n",
    "        \"\"\"\n",
    "        res['IDR'] = res['IDTP'] / np.maximum(1.0, res['IDTP'] + res['IDFN'])\n",
    "        res['IDP'] = res['IDTP'] / np.maximum(1.0, res['IDTP'] + res['IDFP'])\n",
    "        res['IDF1'] = res['IDTP'] / np.maximum(1.0, res['IDTP'] + 0.5 * res['IDFP'] + 0.5 * res['IDFN'])\n",
    "        return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
