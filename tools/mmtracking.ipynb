{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d832b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "     |████████████████████████████████| 52 kB 1.6 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: Click in /opt/conda/lib/python3.9/site-packages (from openmim) (8.0.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from openmim) (2.26.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.9/site-packages (from openmim) (0.8.9)\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.9/site-packages (from openmim) (21.3.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from openmim) (1.3.3)\n",
      "Collecting model-index\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from openmim) (0.4.4)\n",
      "Collecting opendatalab\n",
      "  Downloading opendatalab-0.0.9-py3-none-any.whl (29 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "     |████████████████████████████████| 239 kB 15.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from model-index->openmim) (6.0)\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.9/site-packages (from model-index->openmim) (3.3.6)\n",
      "Collecting ordered-set\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from opendatalab->openmim) (4.62.3)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "     |████████████████████████████████| 2.1 MB 56.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->openmim) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->openmim) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->openmim) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->openmim) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->openmim) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->openmim) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas->openmim) (1.21.4)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 58.7 MB/s            \n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     |████████████████████████████████| 87 kB 9.8 MB/s             \n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown->model-index->openmim) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.6.0)\n",
      "Installing collected packages: mdurl, pygments, markdown-it-py, rich, pycryptodome, ordered-set, opendatalab, model-index, openmim\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.10.0\n",
      "    Uninstalling Pygments-2.10.0:\n",
      "      Successfully uninstalled Pygments-2.10.0\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 model-index-0.1.11 opendatalab-0.0.9 openmim-0.3.9 ordered-set-4.1.0 pycryptodome-3.18.0 pygments-2.15.1 rich-13.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openmim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b447fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
      "Collecting mmtrack\n",
      "  Downloading mmtrack-0.14.0-py3-none-any.whl (400 kB)\n",
      "     |████████████████████████████████| 400 kB 6.3 MB/s            \n",
      "\u001b[?25hCollecting lap\n",
      "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
      "     |████████████████████████████████| 1.5 MB 104.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy<=1.7.3 in /opt/conda/lib/python3.9/site-packages (from mmtrack) (1.7.1)\n",
      "Requirement already satisfied: pandas<=1.3.5 in /opt/conda/lib/python3.9/site-packages (from mmtrack) (1.3.3)\n",
      "Collecting mmcls<1.0.0,>=0.16.0\n",
      "  Downloading mmcls-0.25.0-py2.py3-none-any.whl (648 kB)\n",
      "     |████████████████████████████████| 648 kB 67.2 MB/s            \n",
      "\u001b[?25hCollecting dotty-dict\n",
      "  Downloading dotty_dict-1.3.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from mmtrack) (0.11.2)\n",
      "Collecting attributee\n",
      "  Downloading attributee-0.1.8.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mmtrack) (21.3)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting terminaltables\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mmtrack) (3.4.3)\n",
      "Collecting motmetrics\n",
      "  Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
      "     |████████████████████████████████| 161 kB 67.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from mmtrack) (4.62.3)\n",
      "Collecting mmdet<3.0.0,>=2.19.1\n",
      "  Downloading mmdet-2.28.2-py3-none-any.whl (1.5 MB)\n",
      "     |████████████████████████████████| 1.5 MB 72.6 MB/s            \n",
      "\u001b[?25hCollecting mmcv-full<1.7.0,>=1.3.17\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.6.2-cp39-cp39-manylinux1_x86_64.whl (46.9 MB)\n",
      "     |████████████████████████████████| 46.9 MB 10.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from mmcls<1.0.0,>=0.16.0->mmtrack) (1.21.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmtrack) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmtrack) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmtrack) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmtrack) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mmtrack) (1.3.2)\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.9/site-packages (from mmcv-full<1.7.0,>=1.3.17->mmtrack) (4.5.3.56)\n",
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting yapf\n",
      "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
      "     |████████████████████████████████| 250 kB 75.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from mmcv-full<1.7.0,>=1.3.17->mmtrack) (6.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from mmdet<3.0.0,>=2.19.1->mmtrack) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas<=1.3.5->mmtrack) (2021.3)\n",
      "Collecting xmltodict>=0.12.0\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting platformdirs>=3.5.1\n",
      "  Downloading platformdirs-3.8.1-py3-none-any.whl (16 kB)\n",
      "Collecting tomli>=2.0.1\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting importlib-metadata>=6.6.0\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full<1.7.0,>=1.3.17->mmtrack) (3.6.0)\n",
      "Building wheels for collected packages: attributee, lap, pycocotools\n",
      "  Building wheel for attributee (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for attributee: filename=attributee-0.1.8-py3-none-any.whl size=12878 sha256=32d14e8a4905167c18066ae92a168c4c2a0e7ed01526126cad160933696bae22\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/13/39/93/099c94ba753987bb1ab08c39edb44d9db07c6911301375a6bb\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp39-cp39-linux_x86_64.whl size=1483313 sha256=0acbdfad1e7627af36e66c5cc6510a8a0e72eae92b9627744b30760deedcc1ee\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/2f/8b/30/e7dd4f9dc44fb438381df571c9a6bddc35aafd1bf39c4f8911\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp39-cp39-linux_x86_64.whl size=104409 sha256=fd86908a8bc5ad108df2f0845d176f906118b21f642b73d86e714a8e2a6b8fa0\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/2f/58/25/e78f1f766e904a9071266661d20d0bc6644df86bcd160aba11\n",
      "Successfully built attributee lap pycocotools\n",
      "Installing collected packages: tomli, platformdirs, importlib-metadata, yapf, addict, xmltodict, terminaltables, pycocotools, mmcv-full, motmetrics, mmdet, mmcls, lap, dotty-dict, attributee, mmtrack\n",
      "  Attempting uninstall: tomli\n",
      "    Found existing installation: tomli 1.2.2\n",
      "    Uninstalling tomli-1.2.2:\n",
      "      Successfully uninstalled tomli-1.2.2\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 2.4.0\n",
      "    Uninstalling platformdirs-2.4.0:\n",
      "      Successfully uninstalled platformdirs-2.4.0\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.2\n",
      "    Uninstalling importlib-metadata-4.8.2:\n",
      "      Successfully uninstalled importlib-metadata-4.8.2\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "black 21.12b0 requires tomli<2.0.0,>=0.2.6, but you have tomli 2.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed addict-2.4.0 attributee-0.1.8 dotty-dict-1.3.1 importlib-metadata-6.8.0 lap-0.4.0 mmcls-0.25.0 mmcv-full-1.6.2 mmdet-2.28.2 mmtrack-0.14.0 motmetrics-1.4.0 platformdirs-3.8.1 pycocotools-2.0.6 terminaltables-3.1.10 tomli-2.0.1 xmltodict-0.13.0 yapf-0.40.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mim install mmtrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1e0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'mmtracking' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmtracking.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a88ad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/a_mmtracking/mmtracking\n"
     ]
    }
   ],
   "source": [
    "%cd mmtracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6143dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in /opt/conda/lib/python3.9/site-packages (from -r requirements/build.txt (line 1)) (0.29.24)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from -r requirements/build.txt (line 2)) (1.21.4)\n",
      "Requirement already satisfied: attributee in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 1)) (0.1.8)\n",
      "Requirement already satisfied: dotty_dict in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 2)) (1.3.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 1.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: lap in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 5)) (3.4.3)\n",
      "Requirement already satisfied: mmcls<1.0.0,>=0.16.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 6)) (0.25.0)\n",
      "Requirement already satisfied: motmetrics in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: pandas<=1.3.5 in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 9)) (1.3.3)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 10)) (2.0.6)\n",
      "Requirement already satisfied: scipy<=1.7.3 in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 12)) (0.11.2)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 13)) (3.1.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from -r requirements/runtime.txt (line 14)) (4.62.3)\n",
      "Collecting asynctest\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting codecov\n",
      "  Downloading codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Collecting flake8\n",
      "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 8.4 MB/s             \n",
      "\u001b[?25hCollecting interrogate\n",
      "  Downloading interrogate-1.5.0-py3-none-any.whl (45 kB)\n",
      "     |████████████████████████████████| 45 kB 5.0 MB/s             \n",
      "\u001b[?25hCollecting isort==4.3.21\n",
      "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 2.0 MB/s             \n",
      "\u001b[?25hCollecting kwarray\n",
      "  Downloading kwarray-0.6.13-py3-none-any.whl (105 kB)\n",
      "     |████████████████████████████████| 105 kB 56.6 MB/s            \n",
      "\u001b[?25hCollecting pytest\n",
      "  Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
      "     |████████████████████████████████| 323 kB 68.3 MB/s            \n",
      "\u001b[?25hCollecting ubelt\n",
      "  Downloading ubelt-1.3.2-py3-none-any.whl (215 kB)\n",
      "     |████████████████████████████████| 215 kB 37.1 MB/s            \n",
      "\u001b[?25hCollecting xdoctest>=0.10.0\n",
      "  Downloading xdoctest-1.1.1-py3-none-any.whl (137 kB)\n",
      "     |████████████████████████████████| 137 kB 77.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: yapf in /opt/conda/lib/python3.9/site-packages (from -r requirements/tests.txt (line 11)) (0.40.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements/runtime.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements/runtime.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements/runtime.txt (line 5)) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements/runtime.txt (line 5)) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->-r requirements/runtime.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: xmltodict>=0.12.0 in /opt/conda/lib/python3.9/site-packages (from motmetrics->-r requirements/runtime.txt (line 7)) (0.13.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas<=1.3.5->-r requirements/runtime.txt (line 9)) (2021.3)\n",
      "Collecting coverage\n",
      "  Downloading coverage-7.2.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "     |████████████████████████████████| 228 kB 71.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.9 in /opt/conda/lib/python3.9/site-packages (from codecov->-r requirements/tests.txt (line 2)) (2.26.0)\n",
      "Collecting pycodestyle<2.11.0,>=2.10.0\n",
      "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
      "     |████████████████████████████████| 41 kB 522 kB/s             \n",
      "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0\n",
      "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting pyflakes<3.1.0,>=3.0.0\n",
      "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
      "     |████████████████████████████████| 62 kB 2.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.9/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (0.8.9)\n",
      "Collecting py\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "     |████████████████████████████████| 98 kB 13.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: click>=7.1 in /opt/conda/lib/python3.9/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (8.0.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (0.4.4)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.9/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (21.2.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc8\n",
      "  Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pytest->-r requirements/tests.txt (line 8)) (2.0.1)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from xdoctest>=0.10.0->-r requirements/tests.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.9/site-packages (from yapf->-r requirements/tests.txt (line 11)) (6.8.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.9/site-packages (from yapf->-r requirements/tests.txt (line 11)) (3.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=6.6.0->yapf->-r requirements/tests.txt (line 11)) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (2021.10.8)\n",
      "Installing collected packages: ubelt, toml, pyflakes, pycodestyle, py, pluggy, mccabe, iniconfig, exceptiongroup, coverage, xdoctest, pytest, kwarray, isort, interrogate, flake8, einops, codecov, asynctest\n",
      "Successfully installed asynctest-0.13.0 codecov-2.1.13 coverage-7.2.7 einops-0.6.1 exceptiongroup-1.1.2 flake8-6.0.0 iniconfig-2.0.0 interrogate-1.5.0 isort-4.3.21 kwarray-0.6.13 mccabe-0.7.0 pluggy-1.2.0 py-1.11.0 pycodestyle-2.10.0 pyflakes-3.0.1 pytest-7.4.0 toml-0.10.2 ubelt-1.3.2 xdoctest-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552a077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sys.platform': 'linux',\n",
       " 'Python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]',\n",
       " 'CUDA available': True,\n",
       " 'GPU 0': 'Tesla T4',\n",
       " 'CUDA_HOME': '/opt/conda',\n",
       " 'NVCC': 'Cuda compilation tools, release 11.4, V11.4.48',\n",
       " 'GCC': 'gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0',\n",
       " 'PyTorch': '1.9.1+cu111',\n",
       " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n',\n",
       " 'TorchVision': '0.10.1+cu111',\n",
       " 'OpenCV': '4.5.3',\n",
       " 'MMCV': '1.6.2',\n",
       " 'MMCV Compiler': 'GCC 7.3',\n",
       " 'MMCV CUDA Compiler': '11.1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmcv import collect_env\n",
    "collect_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89c07c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JonathonLuiten/TrackEval.git\n",
      "  Cloning https://github.com/JonathonLuiten/TrackEval.git to /tmp/pip-req-build-r6d2mq8l\n",
      "  Running command git clone --filter=blob:none -q https://github.com/JonathonLuiten/TrackEval.git /tmp/pip-req-build-r6d2mq8l\n",
      "  Resolved https://github.com/JonathonLuiten/TrackEval.git to commit 12c8791b303e0a0b50f753af204249e622d0281a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from trackeval==1.0.dev1) (1.7.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from trackeval==1.0.dev1) (1.21.4)\n",
      "Building wheels for collected packages: trackeval\n",
      "  Building wheel for trackeval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trackeval: filename=trackeval-1.0.dev1-py3-none-any.whl size=149965 sha256=81cefa9a7e9027f36587f7ff05b806498351eceb1c84e931e63f1a2b1e5f968a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4w1thb3w/wheels/f0/6b/7d/5fbdac329a1c60b842344f9109b4ef2042c0bbc3582569cc4d\n",
      "Successfully built trackeval\n",
      "Installing collected packages: trackeval\n",
      "Successfully installed trackeval-1.0.dev1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/JonathonLuiten/TrackEval.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff57e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n",
      "--2023-07-10 08:56:02--  https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 8.25.82.208, 8.25.82.207, 8.25.82.210, ...\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|8.25.82.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# unset the proxy for downloading the pretrained models (optional)\n",
    "!unset https_proxy\n",
    "!unset http_proxy\n",
    "\n",
    "# download checkpoints\n",
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth -P ./checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dba25a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 08:56:19,383 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth'}\n",
      "2023-07-10 08:56:19,385 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\n",
      "2023-07-10 08:56:19,386 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\" to /aiffel/.cache/torch/hub/checkpoints/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb6357065f476497f7deabb861b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/158M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 08:56:38,935 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth'}\n",
      "2023-07-10 08:56:38,936 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth\n",
      "2023-07-10 08:56:38,937 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth\" to /aiffel/.cache/torch/hub/checkpoints/tracktor_reid_r50_iter25245-a452f51f.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593ffbaebcab4efca9f382be5ada528d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 08:56:54,550 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1.5 task/s, elapsed: 5s, ETA:     0s\n",
      " making the output video at ./demo/mot.mp4 with a FPS of 3.0\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 20.9 task/s, elapsed: 0s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# run mot demo\n",
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_mot, init_model\n",
    "mot_config = './configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'\n",
    "input_video = './demo/demo.mp4'\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "# build the model from a config file\n",
    "mot_model = init_model(mot_config, device='cuda:0')\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "# test and show/save the images\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_mot(mot_model, img, frame_id=i)\n",
    "    mot_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            show=False,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "\n",
    "output = './demo/mot.mp4'\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8023e",
   "metadata": {},
   "source": [
    "### Train a MOT model with a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7d9d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "--2023-07-10 08:58:01--  https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 8.25.82.211, 8.25.82.210, 8.25.82.208, ...\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|8.25.82.211|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 344566302 (329M) [application/zip]\n",
      "Saving to: ‘./data/MOT17_tiny.zip.1’\n",
      "\n",
      "MOT17_tiny.zip.1    100%[===================>] 328.60M  6.59MB/s    in 51s     \n",
      "\n",
      "2023-07-10 08:58:52 (6.50 MB/s) - ‘./data/MOT17_tiny.zip.1’ saved [344566302/344566302]\n",
      "\n",
      "replace ./data/MOT17_tiny/train/MOT17-02-FRCNN/det/det.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip -P ./data\n",
    "!unzip -q ./data/MOT17_tiny.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a316f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.75it/s]\n",
      "train has 145 instances.\n",
      "Done! Saved as ./data/MOT17_tiny/annotations/train_cocoformat.json and ./data/MOT17_tiny/annotations/train_detections.pkl\n",
      "Converting test set to COCO format\n",
      "0it [00:00, ?it/s]\n",
      "test has 0 instances.\n",
      "Done! Saved as ./data/MOT17_tiny/annotations/test_cocoformat.json and ./data/MOT17_tiny/annotations/test_detections.pkl\n",
      "Converting half-train set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "half-train has 104 instances.\n",
      "Done! Saved as ./data/MOT17_tiny/annotations/half-train_cocoformat.json and ./data/MOT17_tiny/annotations/half-train_detections.pkl\n",
      "Converting half-val set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.22it/s]\n",
      "half-val has 122 instances.\n",
      "Done! Saved as ./data/MOT17_tiny/annotations/half-val_cocoformat.json and ./data/MOT17_tiny/annotations/half-val_detections.pkl\n",
      "100%|████████████████████████████████████████████| 2/2 [08:59<00:00, 269.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to coco format\n",
    "!python ./tools/convert_datasets/mot/mot2coco.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/annotations --split-train --convert-det\n",
    "# crop pedestrian patches from the original dataset for training reid model. It may take a few minutes.\n",
    "!rm -rf ./data/MOT17_tiny/reid\n",
    "!python ./tools/convert_datasets/mot/mot2reid.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/reid --val-split 0.9 --vis-threshold 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738b133",
   "metadata": {},
   "source": [
    "#### Train a detector for a MOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "669d9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
      "        )))\n",
      "dataset_type = 'CocoDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1088, 1088),\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1088, 1088),\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='RandomCrop',\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "USE_MMDET = True\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "work_dir = './tutorial_exps/detector'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_mot17-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/detector'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.data.workers_per_gpu = 0\n",
    "cfg.device='cuda'\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85489fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:24:26,487 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
      "2023-07-10 09:24:26,488 - mmcv - INFO - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2023-07-10 09:24:26,489 - mmcv - INFO - load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Downloading: \"http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\" to /aiffel/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84c188421c94856909262980dc102e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/160M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:24:44,498 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/mmdet/utils/compat_config.py:28: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  warnings.warn(\n",
      "2023-07-10 09:24:44,859 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2023-07-10 09:24:44,861 - mmdet - INFO - Start running, host: root@wetys5fi8xu8ea77gfi7g5jhs-69768fcb74-hhkzw, work_dir: /aiffel/aiffel/a_mmtracking/mmtracking/tutorial_exps/detector\n",
      "2023-07-10 09:24:44,862 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2023-07-10 09:24:44,863 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
      "2023-07-10 09:24:44,864 - mmdet - INFO - Checkpoints will be saved to /aiffel/aiffel/a_mmtracking/mmtracking/tutorial_exps/detector by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:25:10,963 - mmdet - INFO - Epoch [1][50/414]\tlr: 9.902e-03, eta: 0:13:53, time: 0.519, data_time: 0.141, memory: 3201, loss_rpn_cls: 0.0867, loss_rpn_bbox: 0.1250, loss_cls: 0.4193, acc: 80.2246, loss_bbox: 0.3584, loss: 0.9894\n",
      "2023-07-10 09:25:33,571 - mmdet - INFO - Epoch [1][100/414]\tlr: 1.980e-02, eta: 0:12:36, time: 0.453, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0344, loss_rpn_bbox: 0.1152, loss_cls: 0.3170, acc: 86.7383, loss_bbox: 0.2249, loss: 0.6915\n",
      "2023-07-10 09:25:55,762 - mmdet - INFO - Epoch [1][150/414]\tlr: 2.000e-02, eta: 0:11:50, time: 0.443, data_time: 0.096, memory: 3201, loss_rpn_cls: 0.0413, loss_rpn_bbox: 0.1296, loss_cls: 0.3152, acc: 86.4492, loss_bbox: 0.2218, loss: 0.7079\n",
      "2023-07-10 09:26:17,891 - mmdet - INFO - Epoch [1][200/414]\tlr: 2.000e-02, eta: 0:11:16, time: 0.442, data_time: 0.097, memory: 3201, loss_rpn_cls: 0.0334, loss_rpn_bbox: 0.0939, loss_cls: 0.3016, acc: 87.2695, loss_bbox: 0.2104, loss: 0.6393\n",
      "2023-07-10 09:26:40,479 - mmdet - INFO - Epoch [1][250/414]\tlr: 2.000e-02, eta: 0:10:49, time: 0.452, data_time: 0.100, memory: 3201, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.0784, loss_cls: 0.2631, acc: 88.7012, loss_bbox: 0.1800, loss: 0.5443\n",
      "2023-07-10 09:27:03,103 - mmdet - INFO - Epoch [1][300/414]\tlr: 2.000e-02, eta: 0:10:24, time: 0.452, data_time: 0.102, memory: 3201, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0697, loss_cls: 0.2483, acc: 89.3145, loss_bbox: 0.1649, loss: 0.5021\n",
      "2023-07-10 09:27:25,379 - mmdet - INFO - Epoch [1][350/414]\tlr: 2.000e-02, eta: 0:09:58, time: 0.446, data_time: 0.098, memory: 3201, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0636, loss_cls: 0.2437, acc: 89.5215, loss_bbox: 0.1656, loss: 0.4904\n",
      "2023-07-10 09:27:47,542 - mmdet - INFO - Epoch [1][400/414]\tlr: 2.000e-02, eta: 0:09:33, time: 0.443, data_time: 0.096, memory: 3201, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0717, loss_cls: 0.2309, acc: 90.1914, loss_bbox: 0.1592, loss: 0.4825\n",
      "2023-07-10 09:27:53,844 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2023-07-10 09:28:22,340 - mmdet - INFO - Epoch [2][50/414]\tlr: 2.000e-02, eta: 0:08:52, time: 0.496, data_time: 0.139, memory: 3201, loss_rpn_cls: 0.0129, loss_rpn_bbox: 0.0592, loss_cls: 0.2006, acc: 91.2793, loss_bbox: 0.1388, loss: 0.4115\n",
      "2023-07-10 09:28:44,919 - mmdet - INFO - Epoch [2][100/414]\tlr: 2.000e-02, eta: 0:08:30, time: 0.451, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0529, loss_cls: 0.1910, acc: 91.9883, loss_bbox: 0.1341, loss: 0.3921\n",
      "2023-07-10 09:29:07,148 - mmdet - INFO - Epoch [2][150/414]\tlr: 2.000e-02, eta: 0:08:08, time: 0.445, data_time: 0.097, memory: 3201, loss_rpn_cls: 0.0163, loss_rpn_bbox: 0.0782, loss_cls: 0.2113, acc: 90.8828, loss_bbox: 0.1390, loss: 0.4448\n",
      "2023-07-10 09:29:29,873 - mmdet - INFO - Epoch [2][200/414]\tlr: 2.000e-02, eta: 0:07:46, time: 0.454, data_time: 0.098, memory: 3201, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0604, loss_cls: 0.2003, acc: 91.5918, loss_bbox: 0.1360, loss: 0.4099\n",
      "2023-07-10 09:29:52,244 - mmdet - INFO - Epoch [2][250/414]\tlr: 2.000e-02, eta: 0:07:24, time: 0.448, data_time: 0.098, memory: 3201, loss_rpn_cls: 0.0120, loss_rpn_bbox: 0.0552, loss_cls: 0.1910, acc: 91.9609, loss_bbox: 0.1326, loss: 0.3909\n",
      "2023-07-10 09:30:14,688 - mmdet - INFO - Epoch [2][300/414]\tlr: 2.000e-02, eta: 0:07:01, time: 0.449, data_time: 0.095, memory: 3201, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0489, loss_cls: 0.1880, acc: 92.0020, loss_bbox: 0.1324, loss: 0.3799\n",
      "2023-07-10 09:30:36,471 - mmdet - INFO - Epoch [2][350/414]\tlr: 2.000e-02, eta: 0:06:38, time: 0.435, data_time: 0.093, memory: 3201, loss_rpn_cls: 0.0114, loss_rpn_bbox: 0.0620, loss_cls: 0.1862, acc: 92.0449, loss_bbox: 0.1248, loss: 0.3844\n",
      "2023-07-10 09:30:58,861 - mmdet - INFO - Epoch [2][400/414]\tlr: 2.000e-02, eta: 0:06:16, time: 0.448, data_time: 0.094, memory: 3201, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0473, loss_cls: 0.1817, acc: 92.3105, loss_bbox: 0.1237, loss: 0.3625\n",
      "2023-07-10 09:31:04,934 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
      "2023-07-10 09:31:32,848 - mmdet - INFO - Epoch [3][50/414]\tlr: 2.000e-02, eta: 0:05:43, time: 0.484, data_time: 0.135, memory: 3201, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0463, loss_cls: 0.1812, acc: 92.2656, loss_bbox: 0.1193, loss: 0.3584\n",
      "2023-07-10 09:31:55,580 - mmdet - INFO - Epoch [3][100/414]\tlr: 2.000e-02, eta: 0:05:22, time: 0.455, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0479, loss_cls: 0.1778, acc: 92.3965, loss_bbox: 0.1197, loss: 0.3568\n",
      "2023-07-10 09:32:17,765 - mmdet - INFO - Epoch [3][150/414]\tlr: 2.000e-02, eta: 0:05:00, time: 0.443, data_time: 0.097, memory: 3201, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0467, loss_cls: 0.1725, acc: 92.5605, loss_bbox: 0.1119, loss: 0.3399\n",
      "2023-07-10 09:32:40,224 - mmdet - INFO - Epoch [3][200/414]\tlr: 2.000e-02, eta: 0:04:38, time: 0.449, data_time: 0.095, memory: 3201, loss_rpn_cls: 0.0077, loss_rpn_bbox: 0.0447, loss_cls: 0.1704, acc: 92.6367, loss_bbox: 0.1117, loss: 0.3345\n",
      "2023-07-10 09:33:02,842 - mmdet - INFO - Epoch [3][250/414]\tlr: 2.000e-02, eta: 0:04:16, time: 0.453, data_time: 0.098, memory: 3201, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0486, loss_cls: 0.1652, acc: 93.0566, loss_bbox: 0.1088, loss: 0.3307\n",
      "2023-07-10 09:33:25,196 - mmdet - INFO - Epoch [3][300/414]\tlr: 2.000e-02, eta: 0:03:54, time: 0.447, data_time: 0.096, memory: 3201, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0437, loss_cls: 0.1686, acc: 92.8047, loss_bbox: 0.1173, loss: 0.3382\n",
      "2023-07-10 09:33:47,636 - mmdet - INFO - Epoch [3][350/414]\tlr: 2.000e-02, eta: 0:03:32, time: 0.448, data_time: 0.100, memory: 3201, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0375, loss_cls: 0.1592, acc: 93.2070, loss_bbox: 0.1039, loss: 0.3092\n",
      "2023-07-10 09:34:09,916 - mmdet - INFO - Epoch [3][400/414]\tlr: 2.000e-02, eta: 0:03:09, time: 0.446, data_time: 0.100, memory: 3201, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0373, loss_cls: 0.1539, acc: 93.4043, loss_bbox: 0.1023, loss: 0.3003\n",
      "2023-07-10 09:34:16,097 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
      "2023-07-10 09:34:43,906 - mmdet - INFO - Epoch [4][50/414]\tlr: 2.000e-03, eta: 0:02:40, time: 0.481, data_time: 0.134, memory: 3201, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0314, loss_cls: 0.1412, acc: 94.0273, loss_bbox: 0.0942, loss: 0.2722\n",
      "2023-07-10 09:35:06,536 - mmdet - INFO - Epoch [4][100/414]\tlr: 2.000e-03, eta: 0:02:18, time: 0.453, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0276, loss_cls: 0.1320, acc: 94.4688, loss_bbox: 0.0883, loss: 0.2533\n",
      "2023-07-10 09:35:29,142 - mmdet - INFO - Epoch [4][150/414]\tlr: 2.000e-03, eta: 0:01:56, time: 0.452, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0270, loss_cls: 0.1290, acc: 94.5137, loss_bbox: 0.0860, loss: 0.2470\n",
      "2023-07-10 09:35:51,642 - mmdet - INFO - Epoch [4][200/414]\tlr: 2.000e-03, eta: 0:01:34, time: 0.450, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0275, loss_cls: 0.1290, acc: 94.4766, loss_bbox: 0.0842, loss: 0.2459\n",
      "2023-07-10 09:36:14,348 - mmdet - INFO - Epoch [4][250/414]\tlr: 2.000e-03, eta: 0:01:12, time: 0.454, data_time: 0.100, memory: 3201, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0278, loss_cls: 0.1274, acc: 94.6582, loss_bbox: 0.0881, loss: 0.2471\n",
      "2023-07-10 09:36:37,182 - mmdet - INFO - Epoch [4][300/414]\tlr: 2.000e-03, eta: 0:00:50, time: 0.457, data_time: 0.100, memory: 3201, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0246, loss_cls: 0.1212, acc: 94.7891, loss_bbox: 0.0782, loss: 0.2288\n",
      "2023-07-10 09:36:59,779 - mmdet - INFO - Epoch [4][350/414]\tlr: 2.000e-03, eta: 0:00:28, time: 0.452, data_time: 0.098, memory: 3201, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0271, loss_cls: 0.1325, acc: 94.3457, loss_bbox: 0.0872, loss: 0.2509\n",
      "2023-07-10 09:37:22,616 - mmdet - INFO - Epoch [4][400/414]\tlr: 2.000e-03, eta: 0:00:06, time: 0.457, data_time: 0.099, memory: 3201, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0252, loss_cls: 0.1233, acc: 94.8359, loss_bbox: 0.0825, loss: 0.2362\n",
      "2023-07-10 09:37:28,943 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed207da8",
   "metadata": {},
   "source": [
    "#### Train a ReID for a MOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7f476a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'ReIDDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(128, 256),\n",
      "        share_params=False,\n",
      "        keep_ratio=False,\n",
      "        bbox_clip_border=False,\n",
      "        override=False),\n",
      "    dict(\n",
      "        type='SeqRandomFlip',\n",
      "        share_params=False,\n",
      "        flip_ratio=0.5,\n",
      "        direction='horizontal'),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "    dict(type='ReIDFormatBundle')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/train_9.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(128, 256),\n",
      "                share_params=False,\n",
      "                keep_ratio=False,\n",
      "                bbox_clip_border=False,\n",
      "                override=False),\n",
      "            dict(\n",
      "                type='SeqRandomFlip',\n",
      "                share_params=False,\n",
      "                flip_ratio=0.5,\n",
      "                direction='horizontal'),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "            dict(type='ReIDFormatBundle')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
      "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "TRAIN_REID = True\n",
      "model = dict(\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
      "        )))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=200,\n",
      "    warmup_ratio=0.005,\n",
      "    step=[1])\n",
      "total_epochs = 2\n",
      "work_dir = './tutorial_exps/reid'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_MOT17.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = 'data/MOT17_tiny/reid/meta/train_9.txt'\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "# learning policy\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=200,\n",
    "    warmup_ratio=1.0 / 200,\n",
    "    step=[1])\n",
    "cfg.total_epochs = 2\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/reid'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.data.workers_per_gpu = 0\n",
    "cfg.device='cuda'\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042b2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:37:34,404 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}\n",
      "2023-07-10 09:37:34,405 - mmcv - INFO - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2023-07-10 09:37:34,405 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\" to /aiffel/.cache/torch/hub/checkpoints/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e50d62df0dc4360aa7cd3f5c1b5eeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:37:46,962 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
      "\n",
      "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
      "\n",
      "2023-07-10 09:37:47,050 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2023-07-10 09:37:47,053 - mmdet - INFO - Start running, host: root@wetys5fi8xu8ea77gfi7g5jhs-69768fcb74-hhkzw, work_dir: /aiffel/aiffel/a_mmtracking/mmtracking/tutorial_exps/reid\n",
      "2023-07-10 09:37:47,054 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2023-07-10 09:37:47,054 - mmdet - INFO - workflow: [('train', 1)], max: 2 epochs\n",
      "2023-07-10 09:37:47,055 - mmdet - INFO - Checkpoints will be saved to /aiffel/aiffel/a_mmtracking/mmtracking/tutorial_exps/reid by HardDiskBackend.\n",
      "2023-07-10 09:38:03,875 - mmdet - INFO - Epoch [1][50/1576]\tlr: 2.488e-02, eta: 0:17:13, time: 0.333, data_time: 0.112, memory: 3201, triplet_loss: 0.1042, ce_loss: 0.8330, top-1: 90.7500, loss: 0.9372\n",
      "2023-07-10 09:38:18,700 - mmdet - INFO - Epoch [1][100/1576]\tlr: 4.975e-02, eta: 0:16:00, time: 0.296, data_time: 0.074, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0003, top-1: 100.0000, loss: 0.0003\n",
      "2023-07-10 09:38:33,534 - mmdet - INFO - Epoch [1][150/1576]\tlr: 7.463e-02, eta: 0:15:26, time: 0.297, data_time: 0.074, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:38:48,247 - mmdet - INFO - Epoch [1][200/1576]\tlr: 9.950e-02, eta: 0:15:00, time: 0.294, data_time: 0.074, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:39:02,876 - mmdet - INFO - Epoch [1][250/1576]\tlr: 1.000e-01, eta: 0:14:38, time: 0.293, data_time: 0.072, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:39:17,502 - mmdet - INFO - Epoch [1][300/1576]\tlr: 1.000e-01, eta: 0:14:18, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:39:32,148 - mmdet - INFO - Epoch [1][350/1576]\tlr: 1.000e-01, eta: 0:14:00, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:39:46,834 - mmdet - INFO - Epoch [1][400/1576]\tlr: 1.000e-01, eta: 0:13:42, time: 0.294, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:40:01,550 - mmdet - INFO - Epoch [1][450/1576]\tlr: 1.000e-01, eta: 0:13:26, time: 0.294, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:40:16,235 - mmdet - INFO - Epoch [1][500/1576]\tlr: 1.000e-01, eta: 0:13:10, time: 0.294, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:40:30,899 - mmdet - INFO - Epoch [1][550/1576]\tlr: 1.000e-01, eta: 0:12:54, time: 0.293, data_time: 0.072, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:40:45,561 - mmdet - INFO - Epoch [1][600/1576]\tlr: 1.000e-01, eta: 0:12:38, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:41:00,246 - mmdet - INFO - Epoch [1][650/1576]\tlr: 1.000e-01, eta: 0:12:23, time: 0.294, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:41:14,929 - mmdet - INFO - Epoch [1][700/1576]\tlr: 1.000e-01, eta: 0:12:07, time: 0.294, data_time: 0.072, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:41:29,598 - mmdet - INFO - Epoch [1][750/1576]\tlr: 1.000e-01, eta: 0:11:52, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:41:44,277 - mmdet - INFO - Epoch [1][800/1576]\tlr: 1.000e-01, eta: 0:11:36, time: 0.294, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:41:58,932 - mmdet - INFO - Epoch [1][850/1576]\tlr: 1.000e-01, eta: 0:11:21, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:42:13,594 - mmdet - INFO - Epoch [1][900/1576]\tlr: 1.000e-01, eta: 0:11:06, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:42:28,259 - mmdet - INFO - Epoch [1][950/1576]\tlr: 1.000e-01, eta: 0:10:51, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:42:42,899 - mmdet - INFO - Epoch [1][1000/1576]\tlr: 1.000e-01, eta: 0:10:36, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2023-07-10 09:42:57,533 - mmdet - INFO - Epoch [1][1050/1576]\tlr: 1.000e-01, eta: 0:10:21, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:43:12,177 - mmdet - INFO - Epoch [1][1100/1576]\tlr: 1.000e-01, eta: 0:10:06, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:43:26,812 - mmdet - INFO - Epoch [1][1150/1576]\tlr: 1.000e-01, eta: 0:09:51, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:43:41,464 - mmdet - INFO - Epoch [1][1200/1576]\tlr: 1.000e-01, eta: 0:09:36, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:43:56,157 - mmdet - INFO - Epoch [1][1250/1576]\tlr: 1.000e-01, eta: 0:09:21, time: 0.294, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:44:10,798 - mmdet - INFO - Epoch [1][1300/1576]\tlr: 1.000e-01, eta: 0:09:06, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:44:25,464 - mmdet - INFO - Epoch [1][1350/1576]\tlr: 1.000e-01, eta: 0:08:51, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:44:40,118 - mmdet - INFO - Epoch [1][1400/1576]\tlr: 1.000e-01, eta: 0:08:36, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:44:54,789 - mmdet - INFO - Epoch [1][1450/1576]\tlr: 1.000e-01, eta: 0:08:21, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:45:09,431 - mmdet - INFO - Epoch [1][1500/1576]\tlr: 1.000e-01, eta: 0:08:07, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:45:24,084 - mmdet - INFO - Epoch [1][1550/1576]\tlr: 1.000e-01, eta: 0:07:52, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:45:31,588 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2023-07-10 09:45:50,398 - mmdet - INFO - Epoch [2][50/1576]\tlr: 1.000e-02, eta: 0:07:24, time: 0.331, data_time: 0.110, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:46:05,075 - mmdet - INFO - Epoch [2][100/1576]\tlr: 1.000e-02, eta: 0:07:09, time: 0.294, data_time: 0.073, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:46:19,743 - mmdet - INFO - Epoch [2][150/1576]\tlr: 1.000e-02, eta: 0:06:55, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:46:34,390 - mmdet - INFO - Epoch [2][200/1576]\tlr: 1.000e-02, eta: 0:06:40, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:46:49,012 - mmdet - INFO - Epoch [2][250/1576]\tlr: 1.000e-02, eta: 0:06:26, time: 0.292, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:47:03,605 - mmdet - INFO - Epoch [2][300/1576]\tlr: 1.000e-02, eta: 0:06:11, time: 0.292, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:47:18,246 - mmdet - INFO - Epoch [2][350/1576]\tlr: 1.000e-02, eta: 0:05:57, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:47:32,887 - mmdet - INFO - Epoch [2][400/1576]\tlr: 1.000e-02, eta: 0:05:42, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:47:47,546 - mmdet - INFO - Epoch [2][450/1576]\tlr: 1.000e-02, eta: 0:05:28, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:48:02,197 - mmdet - INFO - Epoch [2][500/1576]\tlr: 1.000e-02, eta: 0:05:13, time: 0.293, data_time: 0.068, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:48:16,833 - mmdet - INFO - Epoch [2][550/1576]\tlr: 1.000e-02, eta: 0:04:59, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:48:31,460 - mmdet - INFO - Epoch [2][600/1576]\tlr: 1.000e-02, eta: 0:04:44, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:48:46,067 - mmdet - INFO - Epoch [2][650/1576]\tlr: 1.000e-02, eta: 0:04:30, time: 0.292, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:49:00,696 - mmdet - INFO - Epoch [2][700/1576]\tlr: 1.000e-02, eta: 0:04:15, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:49:15,314 - mmdet - INFO - Epoch [2][750/1576]\tlr: 1.000e-02, eta: 0:04:00, time: 0.292, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:49:29,928 - mmdet - INFO - Epoch [2][800/1576]\tlr: 1.000e-02, eta: 0:03:46, time: 0.292, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:49:44,563 - mmdet - INFO - Epoch [2][850/1576]\tlr: 1.000e-02, eta: 0:03:31, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:49:59,199 - mmdet - INFO - Epoch [2][900/1576]\tlr: 1.000e-02, eta: 0:03:17, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:50:13,848 - mmdet - INFO - Epoch [2][950/1576]\tlr: 1.000e-02, eta: 0:03:02, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:50:28,506 - mmdet - INFO - Epoch [2][1000/1576]\tlr: 1.000e-02, eta: 0:02:48, time: 0.293, data_time: 0.071, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:50:43,162 - mmdet - INFO - Epoch [2][1050/1576]\tlr: 1.000e-02, eta: 0:02:33, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:50:57,819 - mmdet - INFO - Epoch [2][1100/1576]\tlr: 1.000e-02, eta: 0:02:18, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:51:12,465 - mmdet - INFO - Epoch [2][1150/1576]\tlr: 1.000e-02, eta: 0:02:04, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:51:27,137 - mmdet - INFO - Epoch [2][1200/1576]\tlr: 1.000e-02, eta: 0:01:49, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:51:41,784 - mmdet - INFO - Epoch [2][1250/1576]\tlr: 1.000e-02, eta: 0:01:35, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:51:56,436 - mmdet - INFO - Epoch [2][1300/1576]\tlr: 1.000e-02, eta: 0:01:20, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:52:11,092 - mmdet - INFO - Epoch [2][1350/1576]\tlr: 1.000e-02, eta: 0:01:05, time: 0.293, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:52:25,771 - mmdet - INFO - Epoch [2][1400/1576]\tlr: 1.000e-02, eta: 0:00:51, time: 0.294, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:52:40,416 - mmdet - INFO - Epoch [2][1450/1576]\tlr: 1.000e-02, eta: 0:00:36, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:52:55,069 - mmdet - INFO - Epoch [2][1500/1576]\tlr: 1.000e-02, eta: 0:00:22, time: 0.293, data_time: 0.069, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:53:09,685 - mmdet - INFO - Epoch [2][1550/1576]\tlr: 1.000e-02, eta: 0:00:07, time: 0.292, data_time: 0.070, memory: 3201, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2023-07-10 09:53:17,184 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmtrack.models import build_reid as build_model\n",
    "\n",
    "\n",
    "model = build_model(cfg.model.reid)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68803ee",
   "metadata": {},
   "source": [
    "#### Test the DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be11fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
      "    type='DeepSORT',\n",
      "    motion=dict(type='KalmanFilter', center_only=False),\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
      "    tracker=dict(\n",
      "        type='SortTracker',\n",
      "        obj_score_thr=0.5,\n",
      "        reid=dict(\n",
      "            num_samples=10,\n",
      "            img_scale=(256, 128),\n",
      "            img_norm_cfg=None,\n",
      "            match_score_thr=2.0),\n",
      "        match_iou_thr=0.5,\n",
      "        momentums=None,\n",
      "        num_tentatives=2,\n",
      "        num_frames_retain=100))\n",
      "dataset_type = 'MOTChallengeDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        visibility_thr=-1,\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=1,\n",
      "            frame_range=10,\n",
      "            filter_key_img=True,\n",
      "            method='uniform'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "evaluation = dict(metric=['bbox', 'track'], interval=1)\n",
      "search_metrics = ['MOTA', 'IDF1', 'FN', 'FP', 'IDs', 'MT', 'ML']\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.data.test.test_mode = True\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa4723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:53:21,404 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2023-07-10 09:53:21,405 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2023-07-10 09:53:21,406 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2023-07-10 09:53:21,735 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2023-07-10 09:53:21,736 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2023-07-10 09:53:21,736 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 3.9 task/s, elapsed: 213s, ETA:     0sEvaluate CLEAR MOT results.\n",
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : /opt/conda/lib/python3.9/site-packages/error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : True                          \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "GT_FOLDER            : /tmp/tmpdvfm1tvf              \n",
      "TRACKERS_FOLDER      : /tmp/tmpnhn52ufl              \n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['track']                     \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT17                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   :                               \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : /tmp/tmpnhn52ufl/videoseq.txt \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt_half-val.txt\n",
      "SKIP_SPLIT_FOL       : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 2 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating track\n",
      "\n",
      "1 eval_sequence(MOT17-02-FRCNN, track)                                   0.4134 sec\n",
      "2 eval_sequence(MOT17-04-FRCNN, track)                                   1.3214 sec\n",
      "\n",
      "All sequences for track finished in 1.74 seconds\n",
      "\n",
      "HOTA: track-pedestrian             HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT17-02-FRCNN                     27.476    39.777    19.891    46.774    63.357    21.9      55.754    79.266    30.053    35.864    68.537    24.58     \n",
      "MOT17-04-FRCNN                     44.971    66.962    30.891    71.613    81.87     36.665    50.435    84.814    46.779    52.984    81.784    43.332    \n",
      "COMBINED                           40.329    58.396    28.657    64.407    77.122    33.672    51.662    83.574    42.633    48.49     78.568    38.098    \n",
      "\n",
      "Count: track-pedestrian            Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT17-02-FRCNN                     7294      9880      412       53        \n",
      "MOT17-04-FRCNN                     21149     24178     181       69        \n",
      "COMBINED                           28443     34058     593       122       \n",
      "                IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML   FP   FN  IDs   FM  MOTA  MOTP  IDt IDa IDm      HOTA\n",
      "MOT17-02-FRCNN 28.6% 33.7% 24.9% 56.0% 75.8%  53 13 33  7 1764 4350 1058  397 27.4% 0.224  445 206   8  0.274759\n",
      "MOT17-04-FRCNN 46.3% 49.6% 43.4% 84.7% 96.9%  69 48 20  1  660 3689 1946  336 74.0% 0.173  670  81  10  0.449708\n",
      "OVERALL        41.4% 45.5% 38.0% 76.4% 91.5% 122 61 53  8 2424 8039 3004  733 60.5% 0.184 1115 287  18  0.403289\n",
      "{'IDF1': 0.414, 'IDP': 0.455, 'IDR': 0.38, 'Rcll': 0.764, 'Prcn': 0.915, 'GT': 122, 'MT': 61, 'PT': 53, 'ML': 8, 'FP': 2424, 'FN': 8039, 'IDs': 3004, 'FM': 733, 'MOTA': 0.605, 'MOTP': 0.184, 'IDt': 1115, 'IDa': 287, 'IDm': 18, 'HOTA': 0.403}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataloader\n",
    "from mmtrack.apis import init_model\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmtrack.apis import single_gpu_test\n",
    "from mmtrack.datasets import build_dataset\n",
    "import trackeval\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = init_model(cfg)\n",
    "\n",
    "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "# hard-code way to remove EvalHook args\n",
    "eval_hook_args = [\n",
    "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "    'rule', 'by_epoch'\n",
    "]\n",
    "for key in eval_hook_args:\n",
    "    eval_kwargs.pop(key, None)\n",
    "eval_kwargs.update(dict(metric=['track']))\n",
    "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
